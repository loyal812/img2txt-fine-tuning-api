{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the AI Golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The purpose of the AI Golf swing analysis tool is to help users understand and improve their golf swing by comparing their motion to that of professional players. The tool uses deep neural networks to identify keyframes where significant differences can be observed between the user's and the professional's motions. It also provides interpretable clues to help users intuitively understand these differences. The tool is designed to target fine-grained differences that can be used for self-training, and it uses an unsupervised learning method, which means it doesn't require prior knowledge or labeled data."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\nQuery: What is the purpose of the AI Golf swing analysis tool?\nOriginal Answer: The purpose of the AI Golf swing analysis tool is to help users understand and improve their golf swing by comparing their motion to that of professional players. The tool uses deep neural networks to identify keyframes where significant differences can be observed between the user's and the professional's motions. It also provides interpretable clues to help users intuitively understand these differences. The tool is designed to target fine-grained differences that can be used for self-training, and it uses an unsupervised learning method, which means it doesn't require prior knowledge or labeled data.\nNew Answer: "}, {"role": "assistant", "content": "The AI Golf swing analysis tool is designed to assist users in enhancing their golf swing by comparing their movements to those of professional players. It utilizes deep neural networks to pinpoint frames where the user's and the professional's motions significantly differ. The tool also offers understandable hints to help users intuitively comprehend these differences. It focuses on detailed differences that can be utilized for self-training, and it employs an unsupervised learning approach, eliminating the need for prior knowledge or labeled data."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7). For skeleton inputs,\nan over 0.76 Pearson\u2019s correlation coef\ufb01cient was found\nwhen using the SA-TCC; however, the lowest Pearson\u2019s cor-\nrelation coef\ufb01cient with 0.51 was obtained from the S-TCC\n(Figure 8).\nD. MOTION INTERPOLATION\nFor the qualitative results, we computed and visualized the\nintermediate human pose between a pair of human poses\nconsidering the following three circumstances:\n\u2022The two poses were from a single person. The two poses\nwere in different phases (Figure 9(a)).\n\u2022The two poses were from different individuals. The two\nposes were in the same phase (Figure 9(b)).\n\u2022The two poses were from different individuals. The two\nposes were in different phases (Figure 9(c)).\nVI. DISCUSSION\nA. CASE STUDY\nIn our early case study, we observed that in most cases, when\nthe distance in the latent space was small, the difference\nbetween the two 3D poses was small(Figure 6c). On the\nother hand, when the distance was considerable, the 3D poses\nshowed more differences(Figure 6b, d). This suggested that\nthe network could distinguish between beginners and profes-\nsionals. Thus, we can use this feature to retrieve motion fea-\ntures that help users target the key moves they have to correct.\nHowever, as depicted in Figure 6(a), the distance in the latent\nspace remained large even in certain circumstances where the\nVOLUME 10, 2022 106291\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the SA-TCC network compare to the S-TCC network in terms of performance?\nAnswer: "}, {"role": "assistant", "content": "The SA-TCC network outperforms the S-TCC network. This is evidenced by the Pearson's correlation coefficient, which was over 0.76 for the SA-TCC network, while the S-TCC network achieved a lower coefficient of 0.51. This suggests that the SA-TCC network is more accurate in its predictions."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nCompared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories. In their system, users\nreceived visual, haptic, and audio feedback when they did not\nideally move their bodies or instruments. However, the ideal\nmovement could differ from sport to sport, meaning that it\nmay be dif\ufb01cult to generalize these methodologies to other\nsports.\nOn the other hand, another way to learn sports skills is\nimitating professional players\u2019 motions [1], [3], [4], [5].\nIkeda et al. [16] proposed a golf swing training system that\nuses the motions of professional golfers. In their system,\na user\u2019s motion was synchronized with a selected ideal\nprofessional\u2019s motion, and the two motions were overlaid and\nprojected onto the ground during training. Sasaki et al. [17]\nalso reported the importance of beginners copying expert\nmotions and proposed a climbing training system using pose\nprediction. Their system predicted and visualized the pose of\nexperts based on the user\u2019s current hand and foot positions.\nWhile these recent studies have shown the effectiveness of\nusing multi-modal feedback and the potential of applying\nneural networks to create AI teachers for sports training, it is\ndif\ufb01cult for users to change their motion forms immediately\nto match ideal forms. Thus, building a system that can teach\nusers step-by-step to improve their sports skills remains\nchallenging.\nB. VIDEO AND MOTION ALIGNMENT\nAn ef\ufb01cient way to evaluate whether a person is performing\na motion correctly is to compare their motion with oth-\ners whose motion is considered correct. However, owing\nto the various timings and speeds of motion of different\nVOLUME 10, 2022 106287\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the significance of analyzing the club motion in golf swing analysis?\nAnswer: "}, {"role": "assistant", "content": "The context does not provide information on the significance of analyzing the club motion in golf swing analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion decoder demonstrate its ability to generate new human poses?\nAnswer: "}, {"role": "assistant", "content": "The motion decoder demonstrates its ability to generate new human poses by using a trained network to learn a latent space that shows motion similarity. A high-dimensional data point in this latent space can represent a human pose. To generate an intermediate motion between two points in the latent space, the decoder is trained using latent vectors to predict human poses that are the same as the inputs. The decoder retrieves a new latent vector between the two timing-matched latent vectors using linear interpolation. By adjusting the magnitude parameter, the system can obtain a human pose whose latent vector is closer to the desired pose, thus creating a new human pose that should ideally be more similar to the target poses."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What can be inferred about the arrangement of human poses in the latent space?\nAnswer: "}, {"role": "assistant", "content": "In the latent space, human poses are arranged in such a way that similar motions appear to be close to each other. This arrangement is learned by an encoder that is trained to embed input motions into the latent space. The system can then use this latent space to compare and analyze the differences between two input motions. Furthermore, a high-dimensional data point in this latent space can represent a human pose, allowing the system to generate an intermediate motion between two points in the latent space."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion manipulator in the proposed method contribute to self-training systems?\nAnswer: "}, {"role": "assistant", "content": "The motion manipulator in the proposed method contributes to self-training systems by producing intermediate motions between two different motions. This provides more intuitive instructions for users to learn. It helps in creating new motions that are not seen in the database, which can be beneficial for users to understand and correct their movements."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc. 9th Nordic Conf. Hum.-Comput. Interact., New York, NY, USA,\nOct. 2016, pp. 1\u201310, doi: 10.1145/2971485.2971521.\n[2] C.-C. Liao, D.-H. Hwang, and H. Koike, \u2018\u2018How can i swing like pro?: Golf\nswing analysis tool for self training,\u2019\u2019 in Proc. SIGGRAPH Asia Posters,\nNew York, NY, USA, Dec. 2021, pp. 1\u20132, doi: 10.1145/3476124.3488645.\n[3] P.-H. Han, Y.-S. Chen, Y. Zhong, H.-L. Wang, and Y.-P. Hung, \u2018\u2018My Tai-\nChi coaches: An augmented-learning tool for practicing Tai-Chi Chuan,\u2019\u2019\ninProc. 8th Augmented Hum. Int. Conf., New York, NY, USA, Mar. 2017,\npp. 1\u20134, doi: 10.1145/3041164.3041194.\n[4] I. Kuramoto, Y. Nishimura, K. Yamamoto, Y. Shibuya, and Y. Tsujino,\n\u2018\u2018Visualizing velocity and acceleration on augmented practice mirror self-\nlearning support system of physical motion,\u2019\u2019 in Proc. 2nd IIAI Int.\nConf. Adv. Appl. Informat., Aug. 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep transfer\nlearning for intelligent cellular traf\ufb01c prediction based on cross-domain\nbig data,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1389\u20131401,\nJun. 2019, doi: 10.1109/JSAC.2019.2904363.\n[7] E. Wu and H. Koike, \u2018\u2018FuturePose\u2014Mixed reality martial arts training\nusing real-time 3D human pose forecasting with a RGB camera,\u2019\u2019 in Proc.\nIEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2019, pp. 1384\u20131392,\ndoi:10.1109/WACV.2019.00152.\n[8] K. Shiro, K. Egawa, T. Miyaki, and J. Rekimoto, \u2018\u2018InterPoser: Visual-\nizing interpolated movements for bouldering training,\u2019\u2019 in Proc. IEEE\nConf. Virtual Reality 3D User Inter. (VR), Mar. 2019, pp. 1563\u20131565, doi:\n10.1109/VR.2019.8798366.\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the advantage of providing beginners with a preliminary pose in golf swing training?\nAnswer: "}, {"role": "assistant", "content": "Providing beginners with a preliminary pose in golf swing training allows them to understand the difference between their own swing and that of an expert. This helps them to efficiently learn an ideal form in a gradual manner, rather than directly imitating the ideal motion. The system allows users to choose an ideal form to imitate, enabling them to learn to play sports without the help of coaches during self-training."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\nQuery: What is the advantage of providing beginners with a preliminary pose in golf swing training?\nOriginal Answer: Providing beginners with a preliminary pose in golf swing training allows them to understand the difference between their own swing and that of an expert. This helps them to efficiently learn an ideal form in a gradual manner, rather than directly imitating the ideal motion. The system allows users to choose an ideal form to imitate, enabling them to learn to play sports without the help of coaches during self-training.\nNew Answer: "}, {"role": "assistant", "content": "Offering beginners an initial pose in golf swing training aids them in recognizing the disparities between their own swing and a professional's. This method facilitates a step-by-step learning process, allowing them to gradually perfect their form instead of attempting to mimic the perfect swing immediately. The system gives users the freedom to select a preferred form to replicate, empowering them to engage in self-training without the need for a coach."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the attention-based network focus on different body parts during different phases of a golf swing?\nAnswer: "}, {"role": "assistant", "content": "The attention-based network visualizes attention maps along with the self-attention module to highlight the importance of each body part during different phases of a golf swing. This visualization can help identify which body parts should be focused on and which can be ignored during each phase. The system may also indicate which body parts trainees should pay attention to in order to improve their poses. This approach is intended to aid in discovering crucial points for real training scenarios."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\nQuery: How does the attention-based network focus on different body parts during different phases of a golf swing?\nOriginal Answer: The attention-based network visualizes attention maps along with the self-attention module to highlight the importance of each body part during different phases of a golf swing. This visualization can help identify which body parts should be focused on and which can be ignored during each phase. The system may also indicate which body parts trainees should pay attention to in order to improve their poses. This approach is intended to aid in discovering crucial points for real training scenarios.\nNew Answer: "}, {"role": "assistant", "content": "The attention-based network utilizes attention maps and a self-attention module to emphasize the significance of various body parts throughout the different phases of a golf swing. This allows for the identification of key body parts to concentrate on and those that can be disregarded during each phase. It also suggests which body parts learners should focus on to enhance their poses. The goal of this method is to assist in pinpointing critical aspects for actual training situations."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nCompared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories. In their system, users\nreceived visual, haptic, and audio feedback when they did not\nideally move their bodies or instruments. However, the ideal\nmovement could differ from sport to sport, meaning that it\nmay be dif\ufb01cult to generalize these methodologies to other\nsports.\nOn the other hand, another way to learn sports skills is\nimitating professional players\u2019 motions [1], [3], [4], [5].\nIkeda et al. [16] proposed a golf swing training system that\nuses the motions of professional golfers. In their system,\na user\u2019s motion was synchronized with a selected ideal\nprofessional\u2019s motion, and the two motions were overlaid and\nprojected onto the ground during training. Sasaki et al. [17]\nalso reported the importance of beginners copying expert\nmotions and proposed a climbing training system using pose\nprediction. Their system predicted and visualized the pose of\nexperts based on the user\u2019s current hand and foot positions.\nWhile these recent studies have shown the effectiveness of\nusing multi-modal feedback and the potential of applying\nneural networks to create AI teachers for sports training, it is\ndif\ufb01cult for users to change their motion forms immediately\nto match ideal forms. Thus, building a system that can teach\nusers step-by-step to improve their sports skills remains\nchallenging.\nB. VIDEO AND MOTION ALIGNMENT\nAn ef\ufb01cient way to evaluate whether a person is performing\na motion correctly is to compare their motion with oth-\ners whose motion is considered correct. However, owing\nto the various timings and speeds of motion of different\nVOLUME 10, 2022 106287\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of motion interpolation in the AI Golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The purpose of motion interpolation in the AI Golf swing analysis tool is to provide intermediate human poses between two motions from the latent space. This is based on synchronization and discrepancy detection results. This approach is considered feasible for beginners as they can gradually adjust their pose to match the ideal form. It allows users to understand the differences between their motions and those of various experts during self-training and learn how to improve their motions."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space,\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the proposed method combine different components into a single graphical application?\nAnswer: "}, {"role": "assistant", "content": "The proposed method combines three main components into a single graphical application: a motion synchronizer, a motion discrepancy detector, and a motion manipulator. The motion synchronizer aligns two input motions that have different timings and speeds. The motion discrepancy detector identifies the differences between the two motions and pinpoints the frame where the difference is significant. The motion manipulator generates intermediate motions between the two input motions to provide more intuitive instructions for users. This application allows users to quickly understand the difference between their golf swings and those of professionals during self-training. The users can also observe the step-by-step changes between two selected human poses, helping them to learn an ideal form gradually rather than directly imitating the ideal motion."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\nQuery: How does the proposed method combine different components into a single graphical application?\nOriginal Answer: The proposed method combines three main components into a single graphical application: a motion synchronizer, a motion discrepancy detector, and a motion manipulator. The motion synchronizer aligns two input motions that have different timings and speeds. The motion discrepancy detector identifies the differences between the two motions and pinpoints the frame where the difference is significant. The motion manipulator generates intermediate motions between the two input motions to provide more intuitive instructions for users. This application allows users to quickly understand the difference between their golf swings and those of professionals during self-training. The users can also observe the step-by-step changes between two selected human poses, helping them to learn an ideal form gradually rather than directly imitating the ideal motion.\nNew Answer: "}, {"role": "assistant", "content": "The method in question integrates three primary components into a single graphical application: a motion synchronizer, a motion discrepancy detector, and a motion manipulator. The motion synchronizer aligns two differing motions, accounting for variations in timing and speed. The motion discrepancy detector pinpoints the frame where the difference between the two motions is most pronounced. The motion manipulator creates intermediate motions between the two input motions, offering more intuitive instructions for users. This application aids users in quickly grasping the discrepancies between their golf swings and those of professionals during self-training. It also allows users to observe the gradual changes between two selected human poses, facilitating a step-by-step learning of the ideal form instead of a direct imitation of the perfect motion."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n\npage_label: 106293\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 9. Motion manipulation. Unseen intermediate motions between two different 3D human poses are retrieved from the latent space using\nlinear interpolation. \u03b1is the blending value. The same color of the skeleton denotes the same person.\nmotion showing no difference in the latent space, while\nthe joint difference was signi\ufb01cant. As shown in Figure 7,\na greater correlation and a more clustered distribution were\nfound when the background and golf club were removed from\nthe scene. This indicated that the network could learn the\nmotion features of the club, and that it is essential to analyze\nthe club motion when showing the difference between the two\ninput motions.\nFor the two skeleton models, an over 0.76 Pearson\u2019s corre-\nlation coef\ufb01cient was found when using the SA-TCC. On the\nother hand, only a 0.51 Pearson\u2019s correlation coef\ufb01cient could\nbe obtained from the S-TCC. Therefore, along with the results\nshown in Table 1, we found that although the S-TCC network\nhad the most remarkable performance in tackling synchro-\nnization, its limited ability to detect discrepant motions might\nbe a drawback in terms of real application implementations.\nIn contrast, SA-TCC had a superior Pearson\u2019s correlation\ncoef\ufb01cient over all other competitors while maintaining an\nacceptable phase classi\ufb01cation accuracy. Overall, the skele-\nton model with the attention module implementation outper-\nformed the video models in all aspects of evaluation. There-\nfore, based on the results, we considered the attention module\nthe best choice for actual usage. We then used SA-TCC as\nour \ufb01nal version of the TCC network for the decoder and\napplication implementation, which will be discussed in the\nnext section.\nD. MOTION INTERPOLATION\nFrom the results shown in Figure 9(a), we observed that\nthe trained decoder could restore the ground truth of human\nposes. Furthermore, the motion decoder demonstrated its\nability to generate new human poses unseen in the training\ndataset. This suggested that the TCC network could learn\n\ufb01ne-grained features of the poses of a single person. Notably,\nthe intermediate motion exhibited a continuous change from\none pose to another. From this, We could infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the TCC algorithm in the AI Golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The TCC algorithm in the AI Golf swing analysis tool is used to learn a latent space that shows motion similarity. This high-dimensional data point in latent space can be representative of a human pose. The TCC network is trained to generate an intermediate motion, which is particularly useful for beginners who find it challenging to imitate an ideal motion form. The network is also used to retrieve the intermediate motion between two points in the latent space. This is achieved by training a decoder using latent vectors to predict human poses that are the same as the inputs."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the human pose gradually changed from an\nabnormal to a standard form. This suggested that instead of\nteaching beginners directly with professionals\u2019 swing forms,\nwe could provide them with a preliminary pose that is more\nacceptable for beginners to imitate.\nVII. APPLICATIONS\nThe proposed method can be used for self-training sys-\ntems that detect discrepant motion frames using the distance\nbetween golf swings in the latent space and compare 3D\nhuman poses at the detected frames. As an application proto-\ntype, we combine the motion synchronizer, motion discrep-\nancy detector, and motion manipulator into a single graphical\nVOLUME 10, 2022 106293\nQuery: What is the purpose of the TCC algorithm in the AI Golf swing analysis tool?\nOriginal Answer: The TCC algorithm in the AI Golf swing analysis tool is used to learn a latent space that shows motion similarity. This high-dimensional data point in latent space can be representative of a human pose. The TCC network is trained to generate an intermediate motion, which is particularly useful for beginners who find it challenging to imitate an ideal motion form. The network is also used to retrieve the intermediate motion between two points in the latent space. This is achieved by training a decoder using latent vectors to predict human poses that are the same as the inputs.\nNew Answer: "}, {"role": "assistant", "content": "The TCC algorithm in the AI Golf swing analysis tool serves to learn a latent space that represents motion similarity. It creates a high-dimensional point in this space that corresponds to a specific human pose. The algorithm is trained to generate an intermediate motion, which is beneficial for beginners who struggle to replicate the perfect motion form. The TCC network is also capable of extracting the intermediate motion between two points in the latent space, accomplished by training a decoder with latent vectors to predict human poses identical to the inputs."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the encoder network compress motion sequences in the TCC algorithm?\nAnswer: "}, {"role": "assistant", "content": "The encoder network in the TCC algorithm compresses two motion sequences into latent vectors L1 and L2. For each node of L1, it finds the nearest node of L2. Then, for each identified node of L2, it finds the nearest node of L1, which is a cycle back. If the node cycles back to itself, there is no loss. However, if it doesn't, a TCC loss is calculated."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\nQuery: How does the encoder network compress motion sequences in the TCC algorithm?\nOriginal Answer: The encoder network in the TCC algorithm compresses two motion sequences into latent vectors L1 and L2. For each node of L1, it finds the nearest node of L2. Then, for each identified node of L2, it finds the nearest node of L1, which is a cycle back. If the node cycles back to itself, there is no loss. However, if it doesn't, a TCC loss is calculated.\nNew Answer: "}, {"role": "assistant", "content": "The TCC algorithm's encoder network condenses two motion sequences into latent vectors, known as L1 and L2. Each L1 node is matched with the closest L2 node. A similar process is then performed for each identified L2 node, locating the nearest L1 node in a cyclical manner. If a node cycles back to its original position, no loss is incurred. However, if it does not cycle back, a TCC loss is computed."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What are the three types of networks implemented in the base networks for the TCC algorithm?\nAnswer: "}, {"role": "assistant", "content": "The three types of networks implemented in the base networks for the TCC algorithm are video TCC (V-TCC), skeleton TCC (S-TCC), and skeleton-attention TCC (SA-TCC)."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\nQuery: What are the three types of networks implemented in the base networks for the TCC algorithm?\nOriginal Answer: The three types of networks implemented in the base networks for the TCC algorithm are video TCC (V-TCC), skeleton TCC (S-TCC), and skeleton-attention TCC (SA-TCC).\nNew Answer: "}, {"role": "assistant", "content": "The base networks for the TCC algorithm were implemented in three different types: Video TCC (V-TCC), Skeleton TCC (S-TCC), and Skeleton-Attention TCC (SA-TCC)."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7). For skeleton inputs,\nan over 0.76 Pearson\u2019s correlation coef\ufb01cient was found\nwhen using the SA-TCC; however, the lowest Pearson\u2019s cor-\nrelation coef\ufb01cient with 0.51 was obtained from the S-TCC\n(Figure 8).\nD. MOTION INTERPOLATION\nFor the qualitative results, we computed and visualized the\nintermediate human pose between a pair of human poses\nconsidering the following three circumstances:\n\u2022The two poses were from a single person. The two poses\nwere in different phases (Figure 9(a)).\n\u2022The two poses were from different individuals. The two\nposes were in the same phase (Figure 9(b)).\n\u2022The two poses were from different individuals. The two\nposes were in different phases (Figure 9(c)).\nVI. DISCUSSION\nA. CASE STUDY\nIn our early case study, we observed that in most cases, when\nthe distance in the latent space was small, the difference\nbetween the two 3D poses was small(Figure 6c). On the\nother hand, when the distance was considerable, the 3D poses\nshowed more differences(Figure 6b, d). This suggested that\nthe network could distinguish between beginners and profes-\nsionals. Thus, we can use this feature to retrieve motion fea-\ntures that help users target the key moves they have to correct.\nHowever, as depicted in Figure 6(a), the distance in the latent\nspace remained large even in certain circumstances where the\nVOLUME 10, 2022 106291\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the SA-TCC network differ from the S-TCC network in terms of input?\nAnswer: "}, {"role": "assistant", "content": "The SA-TCC network differs from the S-TCC network in its handling of input. While both networks use skeletons (human poses) as their input, the SA-TCC network incorporates the concept of a self-attention mechanism to better understand the relationship among the 3D joints. This mechanism expands the 3 \u00d7 16 skeleton input into a single 1 \u00d7 48 vector, which is then transformed into a query, key, and value. These are used to create an attention block, which is then fed into the embedder network. The S-TCC network, on the other hand, uses a more straightforward implementation, consisting only of fully-connected layers. It expands the skeleton input to a single 1 \u00d7 48 vector without the use of a self-attention mechanism."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106293\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 9. Motion manipulation. Unseen intermediate motions between two different 3D human poses are retrieved from the latent space using\nlinear interpolation. \u03b1is the blending value. The same color of the skeleton denotes the same person.\nmotion showing no difference in the latent space, while\nthe joint difference was signi\ufb01cant. As shown in Figure 7,\na greater correlation and a more clustered distribution were\nfound when the background and golf club were removed from\nthe scene. This indicated that the network could learn the\nmotion features of the club, and that it is essential to analyze\nthe club motion when showing the difference between the two\ninput motions.\nFor the two skeleton models, an over 0.76 Pearson\u2019s corre-\nlation coef\ufb01cient was found when using the SA-TCC. On the\nother hand, only a 0.51 Pearson\u2019s correlation coef\ufb01cient could\nbe obtained from the S-TCC. Therefore, along with the results\nshown in Table 1, we found that although the S-TCC network\nhad the most remarkable performance in tackling synchro-\nnization, its limited ability to detect discrepant motions might\nbe a drawback in terms of real application implementations.\nIn contrast, SA-TCC had a superior Pearson\u2019s correlation\ncoef\ufb01cient over all other competitors while maintaining an\nacceptable phase classi\ufb01cation accuracy. Overall, the skele-\nton model with the attention module implementation outper-\nformed the video models in all aspects of evaluation. There-\nfore, based on the results, we considered the attention module\nthe best choice for actual usage. We then used SA-TCC as\nour \ufb01nal version of the TCC network for the decoder and\napplication implementation, which will be discussed in the\nnext section.\nD. MOTION INTERPOLATION\nFrom the results shown in Figure 9(a), we observed that\nthe trained decoder could restore the ground truth of human\nposes. Furthermore, the motion decoder demonstrated its\nability to generate new human poses unseen in the training\ndataset. This suggested that the TCC network could learn\n\ufb01ne-grained features of the poses of a single person. Notably,\nthe intermediate motion exhibited a continuous change from\none pose to another. From this, We could infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of the self-attention mechanism in the SA-TCC network?\nAnswer: "}, {"role": "assistant", "content": "The self-attention mechanism in the SA-TCC network is used to recognize the relationships between different skeleton joints. This is achieved by learning the attention matrix inside the attention block. The mechanism expands the 3x16 skeleton input to a single 1x48 vector and then turns it into query, key, and value. The output of the attention block is then fed to the embedder network. This helps the network to understand the interconnections between different joints of the skeleton, thereby enhancing the analysis of the motion sequence."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the human pose gradually changed from an\nabnormal to a standard form. This suggested that instead of\nteaching beginners directly with professionals\u2019 swing forms,\nwe could provide them with a preliminary pose that is more\nacceptable for beginners to imitate.\nVII. APPLICATIONS\nThe proposed method can be used for self-training sys-\ntems that detect discrepant motion frames using the distance\nbetween golf swings in the latent space and compare 3D\nhuman poses at the detected frames. As an application proto-\ntype, we combine the motion synchronizer, motion discrep-\nancy detector, and motion manipulator into a single graphical\nVOLUME 10, 2022 106293\nQuery: What is the role of the self-attention mechanism in the SA-TCC network?\nOriginal Answer: The self-attention mechanism in the SA-TCC network is used to recognize the relationships between different skeleton joints. This is achieved by learning the attention matrix inside the attention block. The mechanism expands the 3x16 skeleton input to a single 1x48 vector and then turns it into query, key, and value. The output of the attention block is then fed to the embedder network. This helps the network to understand the interconnections between different joints of the skeleton, thereby enhancing the analysis of the motion sequence.\nNew Answer: "}, {"role": "assistant", "content": "The self-attention mechanism in the SA-TCC network is crucial for identifying the connections between various parts of the body. It accomplishes this by learning an attention matrix within the attention block. The mechanism transforms the 3x16 skeleton input into a single 1x48 vector, which is then converted into query, key, and value. The result from the attention block is then supplied to the embedder network. This process aids the network in comprehending the interrelationships among different body parts, thus improving the motion sequence analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion discrepancy detector identify fine-grained motion differences?\nAnswer: "}, {"role": "assistant", "content": "The motion discrepancy detector identifies fine-grained motion differences by focusing on the distance between two motions in the latent space. After the network is trained, similar motions are close together in this space. The detector compares two different swing forms, particularly the differences between beginners and experts. The network synchronizes the input sequences by calculating the Euclidean distance between latent vectors, with similar motions appearing close to each other in the latent space. If the poses between the two input motions are dissimilar in a specific frame, causing a large distance between the aligned latent vectors, a significant motion difference may be found in that frame. Therefore, the latent vectors of the input motions, which are timing-matched by the motion synchronizer, are taken and the frame-by-frame distance vector is calculated, indicating the degree of difference between the motions."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the significance of the frame-by-frame distance vector in the motion discrepancy detection process?\nAnswer: "}, {"role": "assistant", "content": "The frame-by-frame distance vector, denoted as D, is crucial in the motion discrepancy detection process as it indicates the degree of difference between two motions. This vector is calculated by taking the latent vectors of the input motions, which are timing-matched by the motion synchronizer, and measuring the distance between them for each frame. If the poses between the two input motions are dissimilar in a specific frame, resulting in a large distance between the aligned latent vectors, a significant motion difference can be detected in that frame. Therefore, this vector plays a key role in identifying fine-grained discrepancies and comparing different swing forms, particularly the differences between beginners and experts."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the TCC network synchronize input sequences?\nAnswer: "}, {"role": "assistant", "content": "The TCC (Temporal Cycle Consistency) network synchronizes input sequences by calculating the Euclidean distance between latent vectors. This process allows similar motions to appear close to each other in the latent space. The network is trained using golf swings of advanced golfers, so a small difference is computed when the input motion is performed similarly to advanced golfers. Conversely, if the poses between the two input motions are dissimilar in a specific frame, causing a large distance between the aligned latent vectors, a significant motion difference in that frame may be identified."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the embedder network in the TCC algorithm?\nAnswer: "}, {"role": "assistant", "content": "The purpose of the embedder network in the Temporal Cycle Consistency (TCC) algorithm is to take the output of the base network and embed it into the latent space. It first stores the features of any given frame along with its context frames over time. Then, it applies 3D convolutions to aggregate the temporal information and reduces the dimensionality using 3D max-pooling. Finally, it uses two fully connected layers and a linear projection to obtain a 128-dimensional embedding for each frame."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\nQuery: What is the purpose of the embedder network in the TCC algorithm?\nOriginal Answer: The purpose of the embedder network in the Temporal Cycle Consistency (TCC) algorithm is to take the output of the base network and embed it into the latent space. It first stores the features of any given frame along with its context frames over time. Then, it applies 3D convolutions to aggregate the temporal information and reduces the dimensionality using 3D max-pooling. Finally, it uses two fully connected layers and a linear projection to obtain a 128-dimensional embedding for each frame.\nNew Answer: "}, {"role": "assistant", "content": "The embedder network in the Temporal Cycle Consistency (TCC) algorithm serves to transform the output of the base network into the latent space. Initially, it records the characteristics of a specific frame and its surrounding frames over time. Following that, it employs 3D convolutions to compile the temporal data and decreases the dimensionality using 3D max-pooling. Ultimately, it utilizes two fully connected layers and a linear projection to generate a 128-dimensional embedding for each frame."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How are features extracted from video or skeleton sequences in the base network of the TCC algorithm?\nAnswer: "}, {"role": "assistant", "content": "In the base network of the Temporal Cycle Consistency (TCC) algorithm, features are extracted from video or skeleton sequences through a base network and an embedder network. The base network is designed to extract features from a given video or skeleton sequence. The embedder network then uses the output of the base network and embeds it into the latent space. For the embedder network, the features of any given frame along with its context frames are stored along the time dimension. Then, 3D convolutions are applied to aggregate the temporal information and the dimensionality is reduced using 3D max-pooling. Finally, two fully connected layers and a linear projection are used to obtain a 128-dimensional embedding for each frame."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\nQuery: How are features extracted from video or skeleton sequences in the base network of the TCC algorithm?\nOriginal Answer: In the base network of the Temporal Cycle Consistency (TCC) algorithm, features are extracted from video or skeleton sequences through a base network and an embedder network. The base network is designed to extract features from a given video or skeleton sequence. The embedder network then uses the output of the base network and embeds it into the latent space. For the embedder network, the features of any given frame along with its context frames are stored along the time dimension. Then, 3D convolutions are applied to aggregate the temporal information and the dimensionality is reduced using 3D max-pooling. Finally, two fully connected layers and a linear projection are used to obtain a 128-dimensional embedding for each frame.\nNew Answer: "}, {"role": "assistant", "content": "The Temporal Cycle Consistency (TCC) algorithm's base network extracts features from video or skeleton sequences. This process involves two networks: the base network and the embedder network. The base network's role is to extract features from the provided video or skeleton sequence. The embedder network then takes the base network's output and embeds it into a latent space. The embedder network stores the features of a frame and its context frames along the time dimension. 3D convolutions are then applied to aggregate this temporal information, and the dimensionality is reduced using 3D max-pooling. The final step involves using two fully connected layers and a linear projection to obtain a 128-dimensional embedding for each frame."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the AI Golf system described in the document?\nAnswer: "}, {"role": "assistant", "content": "The purpose of the AI Golf system described in the document is to provide a golf swing analysis tool using neural networks. This system compares two motion sequences and specifies keyframes where significant differences can be observed between the two motions. It helps users intuitively understand the differences between their own golf swing and that of professional players. The system aims to target the fine-grained differences between users and professionals that can be used for self-training. It uses an unsupervised learning method without prior knowledge and labeled data, which can be beneficial for future applications and research in other sports and skill training processes."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\nQuery: What is the purpose of the AI Golf system described in the document?\nOriginal Answer: The purpose of the AI Golf system described in the document is to provide a golf swing analysis tool using neural networks. This system compares two motion sequences and specifies keyframes where significant differences can be observed between the two motions. It helps users intuitively understand the differences between their own golf swing and that of professional players. The system aims to target the fine-grained differences between users and professionals that can be used for self-training. It uses an unsupervised learning method without prior knowledge and labeled data, which can be beneficial for future applications and research in other sports and skill training processes.\nNew Answer: "}, {"role": "assistant", "content": "The AI Golf system described in the document is designed to assist users in improving their golf swing by comparing their motion sequences with those of professional players. It uses neural networks to identify significant differences in keyframes between the two motions, providing an intuitive understanding of how a user's swing differs from a professional's. The system focuses on the subtle differences that can be used for self-training, employing an unsupervised learning method that doesn't require prior knowledge or labeled data. This approach could potentially be applied to other sports and skill training processes in the future."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the system align two temporal sequences in order to compare them?\nAnswer: "}, {"role": "assistant", "content": "The system uses a method called dynamic time warping (DTW) to align two temporal sequences for comparison. In this process, every index in a sequence is matched with one or more indices from another sequence. The mapping of the indices from the first sequence to the other sequences must be monotonically increasing. This method has been applied in several domains, including golf swing analysis and speech recognition."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n\npage_label: 106295\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nInt.\nConf. Artif. Reality Telexistence Eurographics Symp. Virtual Environ.,\n2018, pp. 171\u2013174, doi: 10.2312/egve.20181330.\n[20] T. Halperin, A. Ephrat, and S. Peleg, \u2018\u2018Dynamic temporal\nalignment of speech to lips,\u2019\u2019 in Proc. IEEE Int. Conf. Acoust.,\nSpeech Signal Process. (ICASSP), May 2019, pp. 3980\u20133984, doi:\n10.1109/ICASSP.2019.8682863.\n[21] I. Misra, C. L. Zitnick, and M. Hebert, \u2018\u2018Shuf\ufb02e and learn: Unsupervised\nlearning using temporal order veri\ufb01cation,\u2019\u2019 in Computer Vision ECCV\n2016 (Lecture Notes in Computer Science), vol. 9905, B. Leibe, J. Matas,\nN. Sebe, and M. Welling, Eds. Cham, Switzerland: Springer, 2016, doi:\n10.1007/978-3-319-46448-0_32.\n[22] P. Sermanet, C. Lynch, Y. Chebotar, J. Hsu, E. Jang, S. Schaal, S. Levine,\nand G. Brain, \u2018\u2018Time-contrastive networks: Self-supervised learning from\nvideo,\u2019\u2019 in Proc. IEEE Int. Conf. Robot. Autom. (ICRA), May 2018,\npp. 1134\u20131141, doi: 10.1109/ICRA.2018.8462891.\n[23] D. Dwibedi, Y. Aytar, J. Tompson, P. Sermanet, and A. Zisserman,\n\u2018\u2018Temporal cycle-consistency learning,\u2019\u2019 in Proc. IEEE/CVF Conf. Com-\nput. Vis. Pattern Recognit. (CVPR), Jun. 2019, pp. 1801\u20131810, doi:\n10.1109/CVPR.2019.00190.\n[24] S. Haresh, S. Kumar, H. Coskun, S. N. Syed, A. Konin, M. Z. Zia, and\nQ.-H. Tran, \u2018\u2018Learning by aligning videos in time,\u2019\u2019 in Proc. IEEE/CVF\nConf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2021, pp. 5544\u20135554,\ndoi:10.1109/CVPR46437.2021.00550.\n[25] H. Seki and Y. Hori, \u2018\u2018Detection of abnormal action using image sequence\nfor monitoring system of aged people,\u2019\u2019 IEEJ Trans. Ind. Appl., vol. 122,\nno. 2, pp. 182\u2013188, 2002, doi: 10.1541/ieejias.122.182.\n[26] G. S. Parra-Dominguez, B. Taati, and A. Mihailidis, \u2018\u20183D human motion\nanalysis to detect abnormal events on stairs,\u2019\u2019 in Proc. 2nd Int. Conf. 3D\nImag., Modeling, Process., Vis. Transmiss., Oct.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of dynamic time warping (DTW) in the alignment process?\nAnswer: "}, {"role": "assistant", "content": "Dynamic Time Warping (DTW) is used to align two temporal sequences. In this process, every index in one sequence is matched with one or more indices from another sequence. The mapping of the indices from the first sequence to the other sequences must be monotonically increasing. This method has been used in various domains, including golf swing projection systems and speech-to-lip movement matching. In the context of golf swing analysis, DTW is used to align the motions of a professional golfer and a user in real-time."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: H. Seki and Y. Hori, \u2018\u2018Detection of abnormal action using image sequence\nfor monitoring system of aged people,\u2019\u2019 IEEJ Trans. Ind. Appl., vol. 122,\nno. 2, pp. 182\u2013188, 2002, doi: 10.1541/ieejias.122.182.\n[26] G. S. Parra-Dominguez, B. Taati, and A. Mihailidis, \u2018\u20183D human motion\nanalysis to detect abnormal events on stairs,\u2019\u2019 in Proc. 2nd Int. Conf. 3D\nImag., Modeling, Process., Vis. Transmiss., Oct. 2012, pp. 97\u2013103, doi:\n10.1109/3DIMPVT.2012.34.\n[27] F. Nater, H. Grabner, and L. Van Gool, \u2018\u2018Exploiting simple hierarchies\nfor unsupervised human behavior analysis,\u2019\u2019 in Proc. IEEE Comput. Soc.\nConf. Comput. Vis. Pattern Recognit. , Jun. 2010, pp. 2014\u20132021, doi:\n10.1109/CVPR.2010.5539877.\n[28] D. Abati, A. Porrello, S. Calderara, and R. Cucchiara, \u2018\u2018Latent space\nautoregression for novelty detection,\u2019\u2019 in Proc. IEEE/CVF Conf. Com-\nput. Vis. Pattern Recognit. (CVPR), Jun. 2019, pp. 481\u2013490, doi:\n10.1109/CVPR.2019.00057.\nQuery: What is the role of dynamic time warping (DTW) in the alignment process?\nOriginal Answer: Dynamic Time Warping (DTW) is used to align two temporal sequences. In this process, every index in one sequence is matched with one or more indices from another sequence. The mapping of the indices from the first sequence to the other sequences must be monotonically increasing. This method has been used in various domains, including golf swing projection systems and speech-to-lip movement matching. In the context of golf swing analysis, DTW is used to align the motions of a professional golfer and a user in real-time.\nNew Answer: "}, {"role": "assistant", "content": "Dynamic Time Warping (DTW) is a technique utilized to align two time-based sequences. It operates by matching each point in one sequence with one or more points in another sequence, ensuring a monotonically increasing mapping from the first sequence to the second. This approach is widely used in several fields, such as aligning the movements of a professional golfer with a user in real-time for golf swing analysis, and matching speech to lip movements."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos. While the time series of 2D poses\ncould roughly represent human motion, 2D poses could vary\nsigni\ufb01cantly owing to camera poses, and it was dif\ufb01cult to\naddress the normalization problem in 2D space. Therefore,\nhuman 3D poses were produced using the simple linear net-\nwork structure proposed in [36]. The estimated 2D poses from\nthe HRNet were fed to a linear network to retrieve the 3D\nhuman poses (Figure 4).\nC. EVALUATION METRICS\nBecause we used a self-supervised learning method,\nwe trained the network until the TCC loss converged. To eval-\nuate how well the network was trained, we applied an accu-\nracy metric showing the precision of the alignment using two\nlabel types: key events and phases. A key event is a single\n106290 VOLUME 10, 2022\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How do self-supervised neural networks contribute to video alignment tasks?\nAnswer: "}, {"role": "assistant", "content": "Self-supervised neural networks contribute to video alignment tasks by compressing input videos into a latent space using an embedder. After this embedding process, a loss is designed to find correspondences through time in the latent space. This encourages the network to learn a latent space where similar motions appear to be close. This method is particularly useful for synchronizing high complexity temporal sequences, such as videos. The loss of the network is based on the temporal cycle-consistency loss, but dynamic time warping is applied along with the loss for smooth temporal matching."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the concept of discrepancy detection in the context of motion analysis?\nAnswer: "}, {"role": "assistant", "content": "Discrepancy detection in the context of motion analysis involves identifying fine-grained differences between two motion sequences. After training a network, similar motions should be close together in a latent space. The distance between two motions in this latent space is then used to detect and retrieve these fine-grained discrepancies. This is particularly useful for comparing different forms of a motion, such as the swings of beginner and expert golfers. If the poses between the two input motions are dissimilar in a specific frame, causing a large distance between the aligned latent vectors, a significant motion difference may be found in that frame. The degree of difference between the motions is indicated by a frame-by-frame distance vector."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How do abnormal events and fine-grained differences differ in the context of motion detection?\nAnswer: "}, {"role": "assistant", "content": "Abnormal events in motion detection refer to patterns in data that do not match the expected behavior. This could include events like falling to the ground. On the other hand, fine-grained differences refer to subtle variations between two regular motions. While a network may be trained to detect abnormal events, the focus of the study is on whether a neural network can be trained to automatically detect these fine-grained differences, which is referred to as discrepancy detection."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of a deep autoencoder in detecting discrepancies in motion sequences?\nAnswer: "}, {"role": "assistant", "content": "The deep autoencoder plays a crucial role in detecting discrepancies in motion sequences. It is first trained with professionals' motion data. After training, the system compresses the user's motions through the network into a latent space. The encoder part of the autoencoder is used to embed the input motions into the latent space, where similar motions appear to be close. The motion synchronizer then matches the timing of the two motions in the latent space by measuring the Euclidean distance between them. The motion discrepancy detector captures the two synchronized latent vectors, measures the difference between them, and passes a distance vector to the motion manipulator. The system then uses the decoder part of the autoencoder to restore the intermediate human poses from the intermediate latent vector for users to gradually improve their motion forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the proposed system use motion synchronization and motion discrepancy detection to improve user forms?\nAnswer: "}, {"role": "assistant", "content": "The proposed system uses motion synchronization and motion discrepancy detection to improve user forms by first capturing user motions and comparing them with those of professionals. The system starts by training a neural network with professionals' motion data. User motions are then compressed through the network into a latent space, where they are compared with the motions of professionals. \n\nFor motion synchronization, the system uses an encoder to embed the input motions into the latent space, where similar motions appear to be close. The timing of the two motions in the latent space is matched by measuring the Euclidean distance between them. \n\nThe motion discrepancy detector then captures the two synchronized latent vectors, measures the difference between them, and passes a distance vector to the motion manipulator. The motion manipulator integrates these vectors to specify the key frames where large differences occur and creates an intermediate latent vector. The system then uses a decoder to restore the intermediate human poses for users to gradually improve their motion forms. \n\nThis process allows the system to provide fine-grained feedback to users, helping them improve their forms by highlighting and correcting the discrepancies between their movements and those of professionals."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the motion manipulator in the system?\nAnswer: "}, {"role": "assistant", "content": "The motion manipulator in the system integrates the two synchronized latent vectors and the distance vector to identify the key frames where large differences occur. It then creates an intermediate latent vector. The system uses a decoder to restore the intermediate human poses from this vector, which allows users to gradually improve their motion forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the system utilize the decoder to restore intermediate human poses?\nAnswer: "}, {"role": "assistant", "content": "The system uses the decoder to restore intermediate human poses from a new latent vector, Vinter, which is obtained through linear interpolation between two timing-matched latent vectors. This process involves training a simple decoder using latent vectors to predict human poses that are the same as the inputs. After training the motion decoder, the new latent vector Vinter is retrieved. The system then uses the decoder to restore the intermediate human poses from Vinter. This allows users to gradually improve their motion forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\n\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the proposed golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The proposed golf swing analysis tool is designed to help users, especially beginners, understand and improve their golf swings by comparing their motions with those of professional players. The tool uses neural networks to identify keyframes where significant differences can be observed between the user's and the professional's motions. It also provides interpretable clues to help users understand these differences and learn how to adjust their movements for better performance. The tool also allows users to gradually imitate intermediate human poses, which can be beneficial for beginners."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\nQuery: What is the purpose of the proposed golf swing analysis tool?\nOriginal Answer: The proposed golf swing analysis tool is designed to help users, especially beginners, understand and improve their golf swings by comparing their motions with those of professional players. The tool uses neural networks to identify keyframes where significant differences can be observed between the user's and the professional's motions. It also provides interpretable clues to help users understand these differences and learn how to adjust their movements for better performance. The tool also allows users to gradually imitate intermediate human poses, which can be beneficial for beginners.\nNew Answer: "}, {"role": "assistant", "content": "The purpose of the proposed golf swing analysis tool is to enable users, particularly novices, to enhance their golf swings. It operates by contrasting their movements with those of expert players using neural networks. The tool identifies crucial frames where the user's and the professional's movements differ significantly. It also offers understandable hints to assist users in comprehending these differences and learning how to modify their actions for improved results. Furthermore, the tool provides an opportunity for users to progressively mimic intermediate human poses, which can be advantageous for beginners."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nframe showing a particular moment, and the phase is a time\nseries between two key events. For example, as shown in\nFigure 5, a key event in golf may be the moment when the golf\nclub hits the ball (impact), and the motion before the golf club\nhits the ball can be considered as the phase of the golf club\napproaching the ball (swinging down). Note that all the\nframes in the period between two key events have the same\nphase label. Following the key event annotation of GolfDB,\nwe labeled our pseudo dataset with eight key events: address,\ntoe-up, mid-backswing, top, mid-downswing, impact, mid-\nfollow-through, and \ufb01nish. Phases were labeled between\nevery two key events, for a total of seven phases.\nThe phase classi\ufb01cation accuracy was per frame phase\nclassi\ufb01cation. To calculate the accuracy, we \ufb01rst used the\nencoders of our TCC networks to extract latent vectors.\nWe then trained a simple classi\ufb01er on the latent vectors to\npredict the labeled phases. The classi\ufb01er was trained under\nseveral conditions by changing the percentage of the given\nlabeled data. After the classi\ufb01er was trained, we used all\nlabeled data to calculate the phase classi\ufb01cation accuracy.\nIn general, the larger the size of the given labeled data, the\nhigher the accuracy of the classi\ufb01er.\nTo explore more speci\ufb01cally the effectiveness of the net-\nwork in detecting discrepant motion, we investigated whether\nthe distance in the latent space could represent the discrep-\nancy between two input sequences by computing Pearson\u2019s\ncorrelation coef\ufb01cient. Because 3D poses varied for differ-\nent camera views, we could not directly compare the two\nhuman poses using the results from the 3d pose estimator.\nThus, we applied Procrustes analysis to align the two human\nposes to ensure that they were seen from the same camera\ndirection. In our experiment, we compared the distance in the\nlatent space with the mean per joint point error (MPJPE) and\nmeasured the Pearson\u2019s correlation coef\ufb01cient \u03c1:\n\u03c1D,E=cov(D, E)\n\u03c3D\u03c3E(6)\nwhere covis the covariance; Dis the distance in the latent\nspace; Eis the MPJPE; and \u03c3Dand\u03c3Eare the standard\ndeviations of DandE.\nV. RESULTS\nThis chapter presents the results of an early qualitative\nanalysis investigating the potential of the proposed method\nto detect discrepant motion differences, followed by more\ndetailed results comparing different modules. Finally, the\nintermediate human poses generated by the motion manip-\nulator are visualized for qualitative studies.\nA. CASE STUDY\nIn our early study, we conducted a qualitative analysis by\nexploring the latent space to investigate whether the network\ncould trace \ufb01ne-grained differences. We \ufb01rst used the V-TCC\nto synchronize the swing motions of professionals and begin-\nners. We then computed the distances between the aligned\nvideos in the latent space and visualized the overlaid 3D\nhuman poses for qualitative comparison (Figure 6).TABLE 1. Phase classification accuracy. This is the accuracy metric\nshowing the ability of the network to classify any given motion frame to\nits corresponding phase.\nB. PHASE CLASSIFICATION ACCURACY\nWe trained the V-TCC using the GolfDB video dataset with\nand without background subtraction. In contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7).\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion synchronizer align motions with different phases and timings?\nAnswer: "}, {"role": "assistant", "content": "The motion synchronizer aligns motions with different phases and timings by embedding the input motions into a latent space using an encoder. In this latent space, similar motions appear to be close. The timing of the two motions in the latent space is then matched by measuring the Euclidean distance between the two motion representations in the latent space. This process ensures that the motions are synchronized despite having different original timings."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of the motion discrepancy detector in the analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The motion discrepancy detector in the analysis tool is responsible for identifying fine-grained differences between two motions. After the network is trained, similar motions are located close together in the latent space. The detector focuses on the distance between two motions in this latent space to find and highlight these discrepancies. Specifically, it compares two different swing forms, particularly the differences between beginners and experts. It takes the latent vectors of the input motions, which are timing-matched by the motion synchronizer, and calculates the frame-by-frame distance vector, which indicates the degree of difference between the motions. If the poses between the two input motions are dissimilar in a specific frame, causing a large distance between the aligned latent vectors, a significant motion difference in that frame may be found."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7). For skeleton inputs,\nan over 0.76 Pearson\u2019s correlation coef\ufb01cient was found\nwhen using the SA-TCC; however, the lowest Pearson\u2019s cor-\nrelation coef\ufb01cient with 0.51 was obtained from the S-TCC\n(Figure 8).\nD. MOTION INTERPOLATION\nFor the qualitative results, we computed and visualized the\nintermediate human pose between a pair of human poses\nconsidering the following three circumstances:\n\u2022The two poses were from a single person. The two poses\nwere in different phases (Figure 9(a)).\n\u2022The two poses were from different individuals. The two\nposes were in the same phase (Figure 9(b)).\n\u2022The two poses were from different individuals. The two\nposes were in different phases (Figure 9(c)).\nVI. DISCUSSION\nA. CASE STUDY\nIn our early case study, we observed that in most cases, when\nthe distance in the latent space was small, the difference\nbetween the two 3D poses was small(Figure 6c). On the\nother hand, when the distance was considerable, the 3D poses\nshowed more differences(Figure 6b, d). This suggested that\nthe network could distinguish between beginners and profes-\nsionals. Thus, we can use this feature to retrieve motion fea-\ntures that help users target the key moves they have to correct.\nHowever, as depicted in Figure 6(a), the distance in the latent\nspace remained large even in certain circumstances where the\nVOLUME 10, 2022 106291\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the proposed SA-TCC network outperform the previous TCC network?\nAnswer: "}, {"role": "assistant", "content": "The SA-TCC network, which stands for Skeleton-Attention Temporal Cycle Consistency, improves upon the previous TCC network by incorporating a self-attention mechanism. This allows the network to recognize the relationships between different skeleton joints by learning the attention matrix inside the attention block. This enhancement leads to a higher Pearson's correlation coefficient when using skeleton inputs, indicating a better performance. Specifically, the SA-TCC network achieved a Pearson's correlation coefficient over 0.76, while the previous S-TCC network, which uses skeletons as its input without the attention mechanism, only achieved a coefficient of 0.51."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\n\npage_label: 106293\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 9. Motion manipulation. Unseen intermediate motions between two different 3D human poses are retrieved from the latent space using\nlinear interpolation. \u03b1is the blending value. The same color of the skeleton denotes the same person.\nmotion showing no difference in the latent space, while\nthe joint difference was signi\ufb01cant. As shown in Figure 7,\na greater correlation and a more clustered distribution were\nfound when the background and golf club were removed from\nthe scene. This indicated that the network could learn the\nmotion features of the club, and that it is essential to analyze\nthe club motion when showing the difference between the two\ninput motions.\nFor the two skeleton models, an over 0.76 Pearson\u2019s corre-\nlation coef\ufb01cient was found when using the SA-TCC. On the\nother hand, only a 0.51 Pearson\u2019s correlation coef\ufb01cient could\nbe obtained from the S-TCC. Therefore, along with the results\nshown in Table 1, we found that although the S-TCC network\nhad the most remarkable performance in tackling synchro-\nnization, its limited ability to detect discrepant motions might\nbe a drawback in terms of real application implementations.\nIn contrast, SA-TCC had a superior Pearson\u2019s correlation\ncoef\ufb01cient over all other competitors while maintaining an\nacceptable phase classi\ufb01cation accuracy. Overall, the skele-\nton model with the attention module implementation outper-\nformed the video models in all aspects of evaluation. There-\nfore, based on the results, we considered the attention module\nthe best choice for actual usage. We then used SA-TCC as\nour \ufb01nal version of the TCC network for the decoder and\napplication implementation, which will be discussed in the\nnext section.\nD. MOTION INTERPOLATION\nFrom the results shown in Figure 9(a), we observed that\nthe trained decoder could restore the ground truth of human\nposes. Furthermore, the motion decoder demonstrated its\nability to generate new human poses unseen in the training\ndataset. This suggested that the TCC network could learn\n\ufb01ne-grained features of the poses of a single person. Notably,\nthe intermediate motion exhibited a continuous change from\none pose to another. From this, We could infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the function of the motion manipulator in the tool?\nAnswer: "}, {"role": "assistant", "content": "The motion manipulator in the tool serves to restore motion from the latent space based on the synchronization and discrepancy detection results. It can retrieve intermediate human poses between two motions that do not exist in the original dataset. This feature is particularly useful for beginners, as instead of directly teaching them professional forms, the motion manipulator can provide them with an intermediate pose that is more acceptable for them to start with."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the human pose gradually changed from an\nabnormal to a standard form. This suggested that instead of\nteaching beginners directly with professionals\u2019 swing forms,\nwe could provide them with a preliminary pose that is more\nacceptable for beginners to imitate.\nVII. APPLICATIONS\nThe proposed method can be used for self-training sys-\ntems that detect discrepant motion frames using the distance\nbetween golf swings in the latent space and compare 3D\nhuman poses at the detected frames. As an application proto-\ntype, we combine the motion synchronizer, motion discrep-\nancy detector, and motion manipulator into a single graphical\nVOLUME 10, 2022 106293\nQuery: What is the function of the motion manipulator in the tool?\nOriginal Answer: The motion manipulator in the tool serves to restore motion from the latent space based on the synchronization and discrepancy detection results. It can retrieve intermediate human poses between two motions that do not exist in the original dataset. This feature is particularly useful for beginners, as instead of directly teaching them professional forms, the motion manipulator can provide them with an intermediate pose that is more acceptable for them to start with.\nNew Answer: "}, {"role": "assistant", "content": "The role of the motion manipulator in the tool is to reconstruct movement from the latent space, taking into account synchronization and discrepancy detection outcomes. It has the ability to extract intermediate human poses between two movements that were not present in the original dataset. This function is especially beneficial for novices, as it allows them to start with an intermediate pose that is easier to mimic, rather than immediately attempting to replicate professional forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc. 9th Nordic Conf. Hum.-Comput. Interact., New York, NY, USA,\nOct. 2016, pp. 1\u201310, doi: 10.1145/2971485.2971521.\n[2] C.-C. Liao, D.-H. Hwang, and H. Koike, \u2018\u2018How can i swing like pro?: Golf\nswing analysis tool for self training,\u2019\u2019 in Proc. SIGGRAPH Asia Posters,\nNew York, NY, USA, Dec. 2021, pp. 1\u20132, doi: 10.1145/3476124.3488645.\n[3] P.-H. Han, Y.-S. Chen, Y. Zhong, H.-L. Wang, and Y.-P. Hung, \u2018\u2018My Tai-\nChi coaches: An augmented-learning tool for practicing Tai-Chi Chuan,\u2019\u2019\ninProc. 8th Augmented Hum. Int. Conf., New York, NY, USA, Mar. 2017,\npp. 1\u20134, doi: 10.1145/3041164.3041194.\n[4] I. Kuramoto, Y. Nishimura, K. Yamamoto, Y. Shibuya, and Y. Tsujino,\n\u2018\u2018Visualizing velocity and acceleration on augmented practice mirror self-\nlearning support system of physical motion,\u2019\u2019 in Proc. 2nd IIAI Int.\nConf. Adv. Appl. Informat., Aug. 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep transfer\nlearning for intelligent cellular traf\ufb01c prediction based on cross-domain\nbig data,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1389\u20131401,\nJun. 2019, doi: 10.1109/JSAC.2019.2904363.\n[7] E. Wu and H. Koike, \u2018\u2018FuturePose\u2014Mixed reality martial arts training\nusing real-time 3D human pose forecasting with a RGB camera,\u2019\u2019 in Proc.\nIEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2019, pp. 1384\u20131392,\ndoi:10.1109/WACV.2019.00152.\n[8] K. Shiro, K. Egawa, T. Miyaki, and J. Rekimoto, \u2018\u2018InterPoser: Visual-\nizing interpolated movements for bouldering training,\u2019\u2019 in Proc. IEEE\nConf. Virtual Reality 3D User Inter. (VR), Mar. 2019, pp. 1563\u20131565, doi:\n10.1109/VR.2019.8798366.\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore,\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the tool help users understand the difference between their swings and those of professional players?\nAnswer: "}, {"role": "assistant", "content": "The tool uses a system that compares two motion sequences and identifies keyframes where significant differences can be observed between the two motions. It helps users intuitively understand the differences between their own swings and those of professional players by providing interpretable clues. The system also restores intermediate human poses between two motions from the latent space, allowing users to gradually change their pose to match the ideal form. This approach allows users to understand and visualize the discrepancy between their own motions and those of experts during self-training, helping them learn how to improve their swings."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\nQuery: How does the tool help users understand the difference between their swings and those of professional players?\nOriginal Answer: The tool uses a system that compares two motion sequences and identifies keyframes where significant differences can be observed between the two motions. It helps users intuitively understand the differences between their own swings and those of professional players by providing interpretable clues. The system also restores intermediate human poses between two motions from the latent space, allowing users to gradually change their pose to match the ideal form. This approach allows users to understand and visualize the discrepancy between their own motions and those of experts during self-training, helping them learn how to improve their swings.\nNew Answer: "}, {"role": "assistant", "content": "The tool employs a comparison system that identifies crucial frames where the user's swing significantly differs from a professional's. It provides intuitive and understandable hints about these differences, aiding users in comprehending the discrepancies between their own and professional swings. The system also recreates intermediate human poses between the two swings, enabling users to progressively adjust their form to align with the optimal one. This method facilitates users in visualizing and understanding the differences between their movements and those of experts during self-training, thereby guiding them on how to enhance their swings."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the potential benefit of using a high-quality motion capture system in the proposed system?\nAnswer: "}, {"role": "assistant", "content": "A high-quality motion capture system in the proposed system can provide accurate and detailed user motion data. This data can then be compared with professional motion data in a neural network trained system to provide fine-grained feedback. This feedback can help users improve their forms by highlighting the differences between their movements and those of professionals. The system can identify key frames where large differences occur and create an intermediate human pose for users to gradually improve their motion forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc. 9th Nordic Conf. Hum.-Comput. Interact., New York, NY, USA,\nOct. 2016, pp. 1\u201310, doi: 10.1145/2971485.2971521.\n[2] C.-C. Liao, D.-H. Hwang, and H. Koike, \u2018\u2018How can i swing like pro?: Golf\nswing analysis tool for self training,\u2019\u2019 in Proc. SIGGRAPH Asia Posters,\nNew York, NY, USA, Dec. 2021, pp. 1\u20132, doi: 10.1145/3476124.3488645.\n[3] P.-H. Han, Y.-S. Chen, Y. Zhong, H.-L. Wang, and Y.-P. Hung, \u2018\u2018My Tai-\nChi coaches: An augmented-learning tool for practicing Tai-Chi Chuan,\u2019\u2019\ninProc. 8th Augmented Hum. Int. Conf., New York, NY, USA, Mar. 2017,\npp. 1\u20134, doi: 10.1145/3041164.3041194.\n[4] I. Kuramoto, Y. Nishimura, K. Yamamoto, Y. Shibuya, and Y. Tsujino,\n\u2018\u2018Visualizing velocity and acceleration on augmented practice mirror self-\nlearning support system of physical motion,\u2019\u2019 in Proc. 2nd IIAI Int.\nConf. Adv. Appl. Informat., Aug. 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep transfer\nlearning for intelligent cellular traf\ufb01c prediction based on cross-domain\nbig data,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1389\u20131401,\nJun. 2019, doi: 10.1109/JSAC.2019.2904363.\n[7] E. Wu and H. Koike, \u2018\u2018FuturePose\u2014Mixed reality martial arts training\nusing real-time 3D human pose forecasting with a RGB camera,\u2019\u2019 in Proc.\nIEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2019, pp. 1384\u20131392,\ndoi:10.1109/WACV.2019.00152.\n[8] K. Shiro, K. Egawa, T. Miyaki, and J. Rekimoto, \u2018\u2018InterPoser: Visual-\nizing interpolated movements for bouldering training,\u2019\u2019 in Proc. IEEE\nConf. Virtual Reality 3D User Inter. (VR), Mar. 2019, pp. 1563\u20131565, doi:\n10.1109/VR.2019.8798366.\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the tool aim to help users learn an ideal form in a gradual manner?\nAnswer: "}, {"role": "assistant", "content": "The tool aims to help users learn an ideal form gradually by allowing them to understand the differences between their own movements and those of experts. Users can select an ideal form to imitate and learn to play sports without the need for a coach. The system provides step-by-step changes between the two selected human poses, enabling users to efficiently learn and adapt their movements."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nCompared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories. In their system, users\nreceived visual, haptic, and audio feedback when they did not\nideally move their bodies or instruments. However, the ideal\nmovement could differ from sport to sport, meaning that it\nmay be dif\ufb01cult to generalize these methodologies to other\nsports.\nOn the other hand, another way to learn sports skills is\nimitating professional players\u2019 motions [1], [3], [4], [5].\nIkeda et al. [16] proposed a golf swing training system that\nuses the motions of professional golfers. In their system,\na user\u2019s motion was synchronized with a selected ideal\nprofessional\u2019s motion, and the two motions were overlaid and\nprojected onto the ground during training. Sasaki et al. [17]\nalso reported the importance of beginners copying expert\nmotions and proposed a climbing training system using pose\nprediction. Their system predicted and visualized the pose of\nexperts based on the user\u2019s current hand and foot positions.\nWhile these recent studies have shown the effectiveness of\nusing multi-modal feedback and the potential of applying\nneural networks to create AI teachers for sports training, it is\ndif\ufb01cult for users to change their motion forms immediately\nto match ideal forms. Thus, building a system that can teach\nusers step-by-step to improve their sports skills remains\nchallenging.\nB. VIDEO AND MOTION ALIGNMENT\nAn ef\ufb01cient way to evaluate whether a person is performing\na motion correctly is to compare their motion with oth-\ners whose motion is considered correct. However, owing\nto the various timings and speeds of motion of different\nVOLUME 10, 2022 106287\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What are some potential applications of the proposed approach in other sports and skill training processes?\nAnswer: "}, {"role": "assistant", "content": "The proposed approach can be applied to other sports and skill training processes due to its ability to analyze and compare motions. It can help users understand the difference between their own movements and those of professionals, and provide intermediate poses that are acceptable during the early learning phase of sports. This method can be particularly useful in sports where the player's standing position is fixed, similar to golf. It can also be used in any training process that involves learning through imitation of expert motions."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nCompared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories. In their system, users\nreceived visual, haptic, and audio feedback when they did not\nideally move their bodies or instruments. However, the ideal\nmovement could differ from sport to sport, meaning that it\nmay be dif\ufb01cult to generalize these methodologies to other\nsports.\nOn the other hand, another way to learn sports skills is\nimitating professional players\u2019 motions [1], [3], [4], [5].\nIkeda et al. [16] proposed a golf swing training system that\nuses the motions of professional golfers. In their system,\na user\u2019s motion was synchronized with a selected ideal\nprofessional\u2019s motion, and the two motions were overlaid and\nprojected onto the ground during training. Sasaki et al. [17]\nalso reported the importance of beginners copying expert\nmotions and proposed a climbing training system using pose\nprediction. Their system predicted and visualized the pose of\nexperts based on the user\u2019s current hand and foot positions.\nWhile these recent studies have shown the effectiveness of\nusing multi-modal feedback and the potential of applying\nneural networks to create AI teachers for sports training, it is\ndif\ufb01cult for users to change their motion forms immediately\nto match ideal forms. Thus, building a system that can teach\nusers step-by-step to improve their sports skills remains\nchallenging.\nB. VIDEO AND MOTION ALIGNMENT\nAn ef\ufb01cient way to evaluate whether a person is performing\na motion correctly is to compare their motion with oth-\ners whose motion is considered correct. However, owing\nto the various timings and speeds of motion of different\nVOLUME 10, 2022 106287\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What are the main contributions of the proposed golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The proposed golf swing analysis tool offers several key contributions. Firstly, it introduces a new method for analyzing golf swings and its potential applications. Secondly, it is able to distinguish when the difference between two motions is large or small. Thirdly, it assists users in understanding how their own movements differ from those of professional players. Fourthly, it provides intermediate poses that are suitable during the early learning phase of sports. Lastly, it discusses important factors that can impact the accuracy of sports analysis."}]}