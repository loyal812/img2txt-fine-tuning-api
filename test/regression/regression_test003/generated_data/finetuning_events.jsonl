{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the AI Golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The purpose of the AI Golf swing analysis tool is to help users understand and improve their golf swing by comparing their motion to that of professional players. The tool uses neural networks to identify keyframes where significant differences can be observed between the user's motion and the professional's motion. It also provides interpretable clues to help users intuitively understand these differences. The system aims to target fine-grained differences that can be used for self-training. It also generates intermediate human poses between two motions to help beginners gradually adjust their pose to match the ideal form."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\nQuery: What is the purpose of the AI Golf swing analysis tool?\nOriginal Answer: The purpose of the AI Golf swing analysis tool is to help users understand and improve their golf swing by comparing their motion to that of professional players. The tool uses neural networks to identify keyframes where significant differences can be observed between the user's motion and the professional's motion. It also provides interpretable clues to help users intuitively understand these differences. The system aims to target fine-grained differences that can be used for self-training. It also generates intermediate human poses between two motions to help beginners gradually adjust their pose to match the ideal form.\nNew Answer: "}, {"role": "assistant", "content": "The AI Golf swing analysis tool is designed to assist users in enhancing their golf swing by contrasting their movements with those of professional players. It utilizes neural networks to pinpoint frames where the user's motion significantly differs from the professional's. The tool offers comprehensible hints to help users intuitively grasp these differences and focuses on subtle differences useful for self-training. Additionally, it creates intermediate human poses between two different motions, aiding beginners in gradually modifying their pose to align with the optimal form."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7). For skeleton inputs,\nan over 0.76 Pearson\u2019s correlation coef\ufb01cient was found\nwhen using the SA-TCC; however, the lowest Pearson\u2019s cor-\nrelation coef\ufb01cient with 0.51 was obtained from the S-TCC\n(Figure 8).\nD. MOTION INTERPOLATION\nFor the qualitative results, we computed and visualized the\nintermediate human pose between a pair of human poses\nconsidering the following three circumstances:\n\u2022The two poses were from a single person. The two poses\nwere in different phases (Figure 9(a)).\n\u2022The two poses were from different individuals. The two\nposes were in the same phase (Figure 9(b)).\n\u2022The two poses were from different individuals. The two\nposes were in different phases (Figure 9(c)).\nVI. DISCUSSION\nA. CASE STUDY\nIn our early case study, we observed that in most cases, when\nthe distance in the latent space was small, the difference\nbetween the two 3D poses was small(Figure 6c). On the\nother hand, when the distance was considerable, the 3D poses\nshowed more differences(Figure 6b, d). This suggested that\nthe network could distinguish between beginners and profes-\nsionals. Thus, we can use this feature to retrieve motion fea-\ntures that help users target the key moves they have to correct.\nHowever, as depicted in Figure 6(a), the distance in the latent\nspace remained large even in certain circumstances where the\nVOLUME 10, 2022 106291\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the SA-TCC network compare to the S-TCC network in terms of performance?\nAnswer: "}, {"role": "assistant", "content": "The SA-TCC network outperforms the S-TCC network. This is evident from the Pearson's correlation coefficient calculated for both networks. The SA-TCC network achieved a correlation coefficient of over 0.76, indicating a strong positive relationship, while the S-TCC network had a lower correlation coefficient of 0.51, indicating a moderate positive relationship. This suggests that the SA-TCC network is more effective in recognizing the relationships between different skeleton joints."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n\npage_label: 106293\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 9. Motion manipulation. Unseen intermediate motions between two different 3D human poses are retrieved from the latent space using\nlinear interpolation. \u03b1is the blending value. The same color of the skeleton denotes the same person.\nmotion showing no difference in the latent space, while\nthe joint difference was signi\ufb01cant. As shown in Figure 7,\na greater correlation and a more clustered distribution were\nfound when the background and golf club were removed from\nthe scene. This indicated that the network could learn the\nmotion features of the club, and that it is essential to analyze\nthe club motion when showing the difference between the two\ninput motions.\nFor the two skeleton models, an over 0.76 Pearson\u2019s corre-\nlation coef\ufb01cient was found when using the SA-TCC. On the\nother hand, only a 0.51 Pearson\u2019s correlation coef\ufb01cient could\nbe obtained from the S-TCC. Therefore, along with the results\nshown in Table 1, we found that although the S-TCC network\nhad the most remarkable performance in tackling synchro-\nnization, its limited ability to detect discrepant motions might\nbe a drawback in terms of real application implementations.\nIn contrast, SA-TCC had a superior Pearson\u2019s correlation\ncoef\ufb01cient over all other competitors while maintaining an\nacceptable phase classi\ufb01cation accuracy. Overall, the skele-\nton model with the attention module implementation outper-\nformed the video models in all aspects of evaluation. There-\nfore, based on the results, we considered the attention module\nthe best choice for actual usage. We then used SA-TCC as\nour \ufb01nal version of the TCC network for the decoder and\napplication implementation, which will be discussed in the\nnext section.\nD. MOTION INTERPOLATION\nFrom the results shown in Figure 9(a), we observed that\nthe trained decoder could restore the ground truth of human\nposes. Furthermore, the motion decoder demonstrated its\nability to generate new human poses unseen in the training\ndataset. This suggested that the TCC network could learn\n\ufb01ne-grained features of the poses of a single person. Notably,\nthe intermediate motion exhibited a continuous change from\none pose to another. From this, We could infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the human pose gradually changed from an\nabnormal to a standard form. This suggested that instead of\nteaching beginners directly with professionals\u2019 swing forms,\nwe could provide them with a preliminary pose that is more\nacceptable for beginners to imitate.\nVII. APPLICATIONS\nThe proposed method can be used for self-training sys-\ntems that detect discrepant motion frames using the distance\nbetween golf swings in the latent space and compare 3D\nhuman poses at the detected frames. As an application proto-\ntype, we combine the motion synchronizer, motion discrep-\nancy detector, and motion manipulator into a single graphical\nVOLUME 10, 2022 106293\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the advantage of using the attention module in the skeleton model?\nAnswer: "}, {"role": "assistant", "content": "The advantage of using the attention module in the skeleton model is that it outperforms the video models in all aspects of evaluation. It has a superior Pearson's correlation coefficient over all other competitors while maintaining an acceptable phase classification accuracy. This makes the attention module the best choice for actual usage. Additionally, the attention-based network can focus on different body parts at different phases, which can be beneficial for detailed analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion decoder demonstrate its ability to generate new human poses?\nAnswer: "}, {"role": "assistant", "content": "The motion decoder demonstrates its ability to generate new human poses by creating an intermediate motion between two points in the latent space. This is achieved by training the decoder using latent vectors to predict human poses that are the same as the inputs. The training set data is first input into the trained TCC network to obtain the outputs of the latent vectors. These latent vectors are then used as inputs to train a simple decoder. The decoder consists of a single fully-connected layer to produce the outputs of the human poses. After training, a new latent vector is retrieved between the two timing-matched latent vectors using linear interpolation. This process allows the decoder to generate a human pose whose latent vector is closer to the second vector, and the restored human pose should ideally be more similar to the human poses generated from the second vector."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What can be inferred about the arrangement of human poses in the latent space?\nAnswer: "}, {"role": "assistant", "content": "In the latent space, human poses are arranged in such a way that similar motions appear to be close to each other. This is achieved by training an encoder to learn this latent space. The system uses this learned latent space to match the timing of two motions by measuring the Euclidean distance between them. Furthermore, a high-dimensional data point in this latent space can represent a human pose."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion decoder generate meaningful intermediate poses?\nAnswer: "}, {"role": "assistant", "content": "The motion decoder generates meaningful intermediate poses by creating an intermediate motion between two points in the latent space. It uses a simple decoder consisting of a single fully-connected layer to produce the outputs of the human poses. The decoder is trained using latent vectors to predict human poses that are the same as the inputs. After training the motion decoder, a new latent vector is retrieved between the two timing-matched latent vectors using linear interpolation. By adjusting the magnitude parameter, a human pose whose latent vector is closer to the second pose can be obtained, and the restored human pose should ideally be more similar to the human poses generated from the second pose."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nCompared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories. In their system, users\nreceived visual, haptic, and audio feedback when they did not\nideally move their bodies or instruments. However, the ideal\nmovement could differ from sport to sport, meaning that it\nmay be dif\ufb01cult to generalize these methodologies to other\nsports.\nOn the other hand, another way to learn sports skills is\nimitating professional players\u2019 motions [1], [3], [4], [5].\nIkeda et al. [16] proposed a golf swing training system that\nuses the motions of professional golfers. In their system,\na user\u2019s motion was synchronized with a selected ideal\nprofessional\u2019s motion, and the two motions were overlaid and\nprojected onto the ground during training. Sasaki et al. [17]\nalso reported the importance of beginners copying expert\nmotions and proposed a climbing training system using pose\nprediction. Their system predicted and visualized the pose of\nexperts based on the user\u2019s current hand and foot positions.\nWhile these recent studies have shown the effectiveness of\nusing multi-modal feedback and the potential of applying\nneural networks to create AI teachers for sports training, it is\ndif\ufb01cult for users to change their motion forms immediately\nto match ideal forms. Thus, building a system that can teach\nusers step-by-step to improve their sports skills remains\nchallenging.\nB. VIDEO AND MOTION ALIGNMENT\nAn ef\ufb01cient way to evaluate whether a person is performing\na motion correctly is to compare their motion with oth-\ners whose motion is considered correct. However, owing\nto the various timings and speeds of motion of different\nVOLUME 10, 2022 106287\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What are the potential applications of the proposed method?\nAnswer: "}, {"role": "assistant", "content": "The proposed method has several applications. It introduces a golf swing analysis method that helps users understand the difference between their own movements and those of professional players. It can also distinguish when the difference between two motions is large or small. Additionally, it provides intermediate poses that are acceptable during the early learning phase of sports. The method also discusses crucial factors that can influence the accuracy of sports analysis."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How can the motion synchronizer, motion discrepancy detector, and motion manipulator be combined?\nAnswer: "}, {"role": "assistant", "content": "The motion synchronizer, motion discrepancy detector, and motion manipulator work together in a system designed to improve users' motion forms. Initially, the system receives two motion inputs and uses an encoder to embed these inputs into a latent space, where similar motions appear to be close. This is done by the motion synchronizer, which matches the timing of the two motions in the latent space by measuring the Euclidean distance between them.\n\nNext, the motion discrepancy detector captures the two synchronized latent vectors, measures the difference between them, and passes a distance vector to the motion manipulator. The motion manipulator then integrates these vectors and identifies key frames where large differences occur, creating an intermediate latent vector.\n\nFinally, the system uses a decoder to restore the intermediate human poses from the intermediate latent vector, allowing users to gradually improve their motion forms. This process allows the system to provide fine-grained feedback to users by comparing their motions with those of professionals."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7). For skeleton inputs,\nan over 0.76 Pearson\u2019s correlation coef\ufb01cient was found\nwhen using the SA-TCC; however, the lowest Pearson\u2019s cor-\nrelation coef\ufb01cient with 0.51 was obtained from the S-TCC\n(Figure 8).\nD. MOTION INTERPOLATION\nFor the qualitative results, we computed and visualized the\nintermediate human pose between a pair of human poses\nconsidering the following three circumstances:\n\u2022The two poses were from a single person. The two poses\nwere in different phases (Figure 9(a)).\n\u2022The two poses were from different individuals. The two\nposes were in the same phase (Figure 9(b)).\n\u2022The two poses were from different individuals. The two\nposes were in different phases (Figure 9(c)).\nVI. DISCUSSION\nA. CASE STUDY\nIn our early case study, we observed that in most cases, when\nthe distance in the latent space was small, the difference\nbetween the two 3D poses was small(Figure 6c). On the\nother hand, when the distance was considerable, the 3D poses\nshowed more differences(Figure 6b, d). This suggested that\nthe network could distinguish between beginners and profes-\nsionals. Thus, we can use this feature to retrieve motion fea-\ntures that help users target the key moves they have to correct.\nHowever, as depicted in Figure 6(a), the distance in the latent\nspace remained large even in certain circumstances where the\nVOLUME 10, 2022 106291\n\npage_label: 106292\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 6. Case study with the V-TCC. The line graph shows the distance between two synchronized motions in the latent space. The red line in the\ngraph indicates the threshold for discrepancy detection. The colored skeleton and black skeleton indicate the user\u2019s pose and expert\u2019s pose,\nrespectively. The density and radius of red spheres indicate the degree of joint position difference between the two skeletons.\nFIGURE 7. Pearson\u2019s correlation test for V-TCC. Left: normal videos. Right:\nvideos without background.\nFIGURE 8. Pearson\u2019s correlation test with skeleton input. Left: S-TCC.\nRight: SA-TCC.\njoint difference was negligible. This might be explained by\nthe fact that the network focused not only on human motion\nbut also on other motion features. In this case, the golf club\u2019s\nmovement, which was also critical during the swing, might\nbe the main factor causing the enormous distance in the latent\nspace. This led us to the following quantitative studies, where\nwe conducted statistical tests to examine the accuracy of the\nsynchronization and the correlation between the latent space\nand joint difference under various conditions.\nB. PHASE CLASSIFICATION ACCURACY\nIn this quantitative study, we discovered that the previous\nTCC implementation had limited precision in terms of syn-\nchronization. As our hypothesis suggests, synchronization\nquality might be in\ufb02uenced by various background informa-\ntion and other movements, such as the golf club\u2019s and human\nshadow\u2019s motions. When the background was removed, a sig-\nni\ufb01cant increase in the accuracy of the V-TCC model was\nobserved. This result supported our hypothesis that infor-\nmation outside the human region would affect alignment.Various types of information from the background, the\nmovement of human shadows, and the motion of properties\ncontrolled by a human might be learned as features by the net-\nwork, thus affecting the accuracy of the analysis. Because of\nthe signi\ufb01cant superiority of the without-background version,\nwe considered it necessary to apply background subtraction\nbefore synchronization when building applications for real\nusage.\nNext, considering the skeleton version, both S-TCC and\nSA-TCC outperformed V-TCC under all conditions. Given\nonly 10% of the labeled data, both S-TCC and SA-TCC\nachieved a phase classi\ufb01cation accuracy of over 90%. This\nmight be explained by the fact that the skeleton version\nhad more compressed and precise information than the\nvideo version, where the color information might be noisy.\nAdditionally, 3D poses represented high-level human fea-\ntures. Therefore, the features outside the human region were\nremoved when retrieving 3D human poses, resulting in more\nprecise accuracy for further golf swing analysis. Note that the\nskeleton data were the estimated results from the video data,\nand the estimation could not be perfect for every human pose.\nDespite imperfect skeleton inputs, the S-TCC and SA-TCC\nnetworks outperformed V-TCC. This result suggested that we\ncould use the skeleton version for more precise implementa-\ntion in actual usage.\nFinally, comparing the two skeleton version mod-\nels, S-TCC performed better than SA-TCC under most\nconditions. However, SA-TCC remained competitive in some\ncircumstances (better than S-TCC with 10% labeled data).\nThis led to the following correlation test, in which we dis-\ncussed the ability of the networks to detect discrepancies\nbetween two motions.\nC. CORRELATION\nDiscussing the correlation test, as shown in Figure 7,\nwe observed a correlation between the distance in the latent\nspace and the MPJPE. While the distribution of the data pairs\nseemed to be scattered, a Pearson\u2019s correlation coef\ufb01cient of\nover 0.69 showed the potential of the network to distinguish\nwhether the difference between the two motions was small\nor large. However, as discussed in the case study section,\nin some circumstances, the network failed to detect discrepant\n106292 VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the significance of the Pearson's correlation coefficient in evaluating the skeleton models?\nAnswer: "}, {"role": "assistant", "content": "The Pearson's correlation coefficient is used to evaluate the correlation between the distance in the latent space and the Mean Per Joint Position Error (MPJPE) in the skeleton models. A higher coefficient indicates a stronger correlation, suggesting that the network can effectively distinguish whether the difference between two motions is small or large. For instance, a Pearson's correlation coefficient over 0.76 was found when using the SA-TCC model, indicating a strong correlation. However, the lowest coefficient of 0.51 was obtained from the S-TCC model, suggesting a weaker correlation."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nCompared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories. In their system, users\nreceived visual, haptic, and audio feedback when they did not\nideally move their bodies or instruments. However, the ideal\nmovement could differ from sport to sport, meaning that it\nmay be dif\ufb01cult to generalize these methodologies to other\nsports.\nOn the other hand, another way to learn sports skills is\nimitating professional players\u2019 motions [1], [3], [4], [5].\nIkeda et al. [16] proposed a golf swing training system that\nuses the motions of professional golfers. In their system,\na user\u2019s motion was synchronized with a selected ideal\nprofessional\u2019s motion, and the two motions were overlaid and\nprojected onto the ground during training. Sasaki et al. [17]\nalso reported the importance of beginners copying expert\nmotions and proposed a climbing training system using pose\nprediction. Their system predicted and visualized the pose of\nexperts based on the user\u2019s current hand and foot positions.\nWhile these recent studies have shown the effectiveness of\nusing multi-modal feedback and the potential of applying\nneural networks to create AI teachers for sports training, it is\ndif\ufb01cult for users to change their motion forms immediately\nto match ideal forms. Thus, building a system that can teach\nusers step-by-step to improve their sports skills remains\nchallenging.\nB. VIDEO AND MOTION ALIGNMENT\nAn ef\ufb01cient way to evaluate whether a person is performing\na motion correctly is to compare their motion with oth-\ners whose motion is considered correct. However, owing\nto the various timings and speeds of motion of different\nVOLUME 10, 2022 106287\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion manipulation feature work in the AI Golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The motion manipulation feature in the AI Golf swing analysis tool allows users to gradually imitate intermediate human poses. Instead of directly imitating the selected motion of a professional, users can use this tool to slowly adapt their form. The tool can also provide an intermediate pose that is more acceptable for beginners to start with. This allows users to understand the continuous changes step-by-step between their current pose and the selected professional pose, helping them to learn an ideal form in a gradual manner."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n\npage_label: 106293\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 9. Motion manipulation. Unseen intermediate motions between two different 3D human poses are retrieved from the latent space using\nlinear interpolation. \u03b1is the blending value. The same color of the skeleton denotes the same person.\nmotion showing no difference in the latent space, while\nthe joint difference was signi\ufb01cant. As shown in Figure 7,\na greater correlation and a more clustered distribution were\nfound when the background and golf club were removed from\nthe scene. This indicated that the network could learn the\nmotion features of the club, and that it is essential to analyze\nthe club motion when showing the difference between the two\ninput motions.\nFor the two skeleton models, an over 0.76 Pearson\u2019s corre-\nlation coef\ufb01cient was found when using the SA-TCC. On the\nother hand, only a 0.51 Pearson\u2019s correlation coef\ufb01cient could\nbe obtained from the S-TCC. Therefore, along with the results\nshown in Table 1, we found that although the S-TCC network\nhad the most remarkable performance in tackling synchro-\nnization, its limited ability to detect discrepant motions might\nbe a drawback in terms of real application implementations.\nIn contrast, SA-TCC had a superior Pearson\u2019s correlation\ncoef\ufb01cient over all other competitors while maintaining an\nacceptable phase classi\ufb01cation accuracy. Overall, the skele-\nton model with the attention module implementation outper-\nformed the video models in all aspects of evaluation. There-\nfore, based on the results, we considered the attention module\nthe best choice for actual usage. We then used SA-TCC as\nour \ufb01nal version of the TCC network for the decoder and\napplication implementation, which will be discussed in the\nnext section.\nD. MOTION INTERPOLATION\nFrom the results shown in Figure 9(a), we observed that\nthe trained decoder could restore the ground truth of human\nposes. Furthermore, the motion decoder demonstrated its\nability to generate new human poses unseen in the training\ndataset. This suggested that the TCC network could learn\n\ufb01ne-grained features of the poses of a single person. Notably,\nthe intermediate motion exhibited a continuous change from\none pose to another. From this, We could infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the TCC algorithm in the AI Golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The TCC (Temporal Cycle Consistency) algorithm in the AI Golf swing analysis tool is used to learn a latent space that shows motion similarity. It is trained to understand that a high-dimensional data point in this latent space can be representative of a human pose. The TCC network is also used to generate an intermediate motion between two different human poses, which can be useful for beginners during self-training. This is achieved by training a decoder using latent vectors to predict human poses that are the same as the inputs. The TCC network is also used to synchronize two latent vectors for the purpose of motion interpolation."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the human pose gradually changed from an\nabnormal to a standard form. This suggested that instead of\nteaching beginners directly with professionals\u2019 swing forms,\nwe could provide them with a preliminary pose that is more\nacceptable for beginners to imitate.\nVII. APPLICATIONS\nThe proposed method can be used for self-training sys-\ntems that detect discrepant motion frames using the distance\nbetween golf swings in the latent space and compare 3D\nhuman poses at the detected frames. As an application proto-\ntype, we combine the motion synchronizer, motion discrep-\nancy detector, and motion manipulator into a single graphical\nVOLUME 10, 2022 106293\nQuery: What is the purpose of the TCC algorithm in the AI Golf swing analysis tool?\nOriginal Answer: The TCC (Temporal Cycle Consistency) algorithm in the AI Golf swing analysis tool is used to learn a latent space that shows motion similarity. It is trained to understand that a high-dimensional data point in this latent space can be representative of a human pose. The TCC network is also used to generate an intermediate motion between two different human poses, which can be useful for beginners during self-training. This is achieved by training a decoder using latent vectors to predict human poses that are the same as the inputs. The TCC network is also used to synchronize two latent vectors for the purpose of motion interpolation.\nNew Answer: "}, {"role": "assistant", "content": "The TCC algorithm in the AI Golf swing analysis tool serves to learn a motion similarity in a latent space. It's trained to comprehend that a data point in this space can symbolize a human pose. The TCC network also creates an intermediate motion between two distinct human poses, which can be beneficial for novices during self-training. This is accomplished by training a decoder with latent vectors to forecast human poses identical to the inputs. Additionally, the TCC network synchronizes two latent vectors for motion interpolation."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the encoder network compress motion sequences in the TCC algorithm?\nAnswer: "}, {"role": "assistant", "content": "The encoder network in the TCC algorithm compresses two motion sequences into latent vectors L1 and L2. For each node of L1, it finds the nearest node of L2. Then, for each identified node of L2, it finds the nearest node of L1, cycling back. If the node cycles back to itself, there is no loss; otherwise, TCC loss is calculated. The encoder network is implemented as a video-based network and two skeleton-based networks, each consisting of a base network and an embedder network. The base network extracts features from a given video or skeleton sequence, while the embedder network uses the output of the base network and embeds it into the latent space."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\nQuery: How does the encoder network compress motion sequences in the TCC algorithm?\nOriginal Answer: The encoder network in the TCC algorithm compresses two motion sequences into latent vectors L1 and L2. For each node of L1, it finds the nearest node of L2. Then, for each identified node of L2, it finds the nearest node of L1, cycling back. If the node cycles back to itself, there is no loss; otherwise, TCC loss is calculated. The encoder network is implemented as a video-based network and two skeleton-based networks, each consisting of a base network and an embedder network. The base network extracts features from a given video or skeleton sequence, while the embedder network uses the output of the base network and embeds it into the latent space.\nNew Answer: "}, {"role": "assistant", "content": "The TCC algorithm's encoder network condenses two motion sequences into latent vectors, L1 and L2. It identifies the closest node of L2 for each L1 node, and vice versa, creating a cycle. If the cycle returns to the original node, there is no loss. Otherwise, the TCC loss is computed. This encoder network is realized through a video-based network and two skeleton-based networks. Each of these networks is made up of a base network, which extracts features from a video or skeleton sequence, and an embedder network, which takes the base network's output and embeds it into the latent space."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What are the three types of networks implemented in the base networks for the TCC algorithm?\nAnswer: "}, {"role": "assistant", "content": "The three types of networks implemented in the base networks for the TCC algorithm are video TCC (V-TCC), skeleton TCC (S-TCC), and skeleton-attention TCC (SA-TCC)."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\nQuery: What are the three types of networks implemented in the base networks for the TCC algorithm?\nOriginal Answer: The three types of networks implemented in the base networks for the TCC algorithm are video TCC (V-TCC), skeleton TCC (S-TCC), and skeleton-attention TCC (SA-TCC).\nNew Answer: "}, {"role": "assistant", "content": "The base networks for the TCC algorithm implemented three types of networks: Video TCC (V-TCC), Skeleton TCC (S-TCC), and Skeleton-Attention TCC (SA-TCC)."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7). For skeleton inputs,\nan over 0.76 Pearson\u2019s correlation coef\ufb01cient was found\nwhen using the SA-TCC; however, the lowest Pearson\u2019s cor-\nrelation coef\ufb01cient with 0.51 was obtained from the S-TCC\n(Figure 8).\nD. MOTION INTERPOLATION\nFor the qualitative results, we computed and visualized the\nintermediate human pose between a pair of human poses\nconsidering the following three circumstances:\n\u2022The two poses were from a single person. The two poses\nwere in different phases (Figure 9(a)).\n\u2022The two poses were from different individuals. The two\nposes were in the same phase (Figure 9(b)).\n\u2022The two poses were from different individuals. The two\nposes were in different phases (Figure 9(c)).\nVI. DISCUSSION\nA. CASE STUDY\nIn our early case study, we observed that in most cases, when\nthe distance in the latent space was small, the difference\nbetween the two 3D poses was small(Figure 6c). On the\nother hand, when the distance was considerable, the 3D poses\nshowed more differences(Figure 6b, d). This suggested that\nthe network could distinguish between beginners and profes-\nsionals. Thus, we can use this feature to retrieve motion fea-\ntures that help users target the key moves they have to correct.\nHowever, as depicted in Figure 6(a), the distance in the latent\nspace remained large even in certain circumstances where the\nVOLUME 10, 2022 106291\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the SA-TCC network differ from the S-TCC network in terms of input?\nAnswer: "}, {"role": "assistant", "content": "The SA-TCC network differs from the S-TCC network in terms of how they handle the skeleton input. While the S-TCC network uses a straightforward implementation that uses skeletons as its input and consists of only fully-connected layers, the SA-TCC network uses the concept of the self-attention mechanism. It expands the skeleton input and turns it into a query, key, and value. This allows the network to recognize the relationships between different skeleton joints by learning the attention matrix inside the attention block."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106293\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 9. Motion manipulation. Unseen intermediate motions between two different 3D human poses are retrieved from the latent space using\nlinear interpolation. \u03b1is the blending value. The same color of the skeleton denotes the same person.\nmotion showing no difference in the latent space, while\nthe joint difference was signi\ufb01cant. As shown in Figure 7,\na greater correlation and a more clustered distribution were\nfound when the background and golf club were removed from\nthe scene. This indicated that the network could learn the\nmotion features of the club, and that it is essential to analyze\nthe club motion when showing the difference between the two\ninput motions.\nFor the two skeleton models, an over 0.76 Pearson\u2019s corre-\nlation coef\ufb01cient was found when using the SA-TCC. On the\nother hand, only a 0.51 Pearson\u2019s correlation coef\ufb01cient could\nbe obtained from the S-TCC. Therefore, along with the results\nshown in Table 1, we found that although the S-TCC network\nhad the most remarkable performance in tackling synchro-\nnization, its limited ability to detect discrepant motions might\nbe a drawback in terms of real application implementations.\nIn contrast, SA-TCC had a superior Pearson\u2019s correlation\ncoef\ufb01cient over all other competitors while maintaining an\nacceptable phase classi\ufb01cation accuracy. Overall, the skele-\nton model with the attention module implementation outper-\nformed the video models in all aspects of evaluation. There-\nfore, based on the results, we considered the attention module\nthe best choice for actual usage. We then used SA-TCC as\nour \ufb01nal version of the TCC network for the decoder and\napplication implementation, which will be discussed in the\nnext section.\nD. MOTION INTERPOLATION\nFrom the results shown in Figure 9(a), we observed that\nthe trained decoder could restore the ground truth of human\nposes. Furthermore, the motion decoder demonstrated its\nability to generate new human poses unseen in the training\ndataset. This suggested that the TCC network could learn\n\ufb01ne-grained features of the poses of a single person. Notably,\nthe intermediate motion exhibited a continuous change from\none pose to another. From this, We could infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the self-attention mechanism in the SA-TCC network?\nAnswer: "}, {"role": "assistant", "content": "The purpose of the self-attention mechanism in the SA-TCC network is to enable the network to recognize the relationships between different skeleton joints. This is achieved by learning the attention matrix inside the attention block."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the human pose gradually changed from an\nabnormal to a standard form. This suggested that instead of\nteaching beginners directly with professionals\u2019 swing forms,\nwe could provide them with a preliminary pose that is more\nacceptable for beginners to imitate.\nVII. APPLICATIONS\nThe proposed method can be used for self-training sys-\ntems that detect discrepant motion frames using the distance\nbetween golf swings in the latent space and compare 3D\nhuman poses at the detected frames. As an application proto-\ntype, we combine the motion synchronizer, motion discrep-\nancy detector, and motion manipulator into a single graphical\nVOLUME 10, 2022 106293\nQuery: What is the purpose of the self-attention mechanism in the SA-TCC network?\nOriginal Answer: The purpose of the self-attention mechanism in the SA-TCC network is to enable the network to recognize the relationships between different skeleton joints. This is achieved by learning the attention matrix inside the attention block.\nNew Answer: "}, {"role": "assistant", "content": "The self-attention mechanism in the SA-TCC network serves to allow the network to discern the relationships among various skeletal joints. It accomplishes this by learning the attention matrix within the attention block, focusing on different body parts at different phases, and observing the intensity of the network's attention through the density and radius of red spheres. This mechanism also enables the network to generate meaningful intermediate poses and detect discrepancies in motion frames."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion discrepancy detector in the AI Golf swing analysis tool detect fine-grained motion differences?\nAnswer: "}, {"role": "assistant", "content": "The motion discrepancy detector in the AI Golf swing analysis tool captures the two synchronized latent vectors, measures the difference between them, and passes a distance vector to the motion manipulator. This process allows the system to detect fine-grained differences between two input motions."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the significance of the frame-by-frame distance vector in the motion discrepancy detector?\nAnswer: "}, {"role": "assistant", "content": "The frame-by-frame distance vector in the motion discrepancy detector indicates the degree of difference between two motions. It is calculated using the latent vectors of the input motions, which are timing-matched by the motion synchronizer. If the poses between the two input motions are dissimilar in a specific frame, causing a large distance between the aligned latent vectors, a significant motion difference in that frame may be identified. This helps in detecting and retrieving fine-grained discrepancies and comparing two different swing forms, particularly for the differences between beginners and experts."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the TCC network synchronize input sequences?\nAnswer: "}, {"role": "assistant", "content": "The TCC (Temporal Cycle Consistency) network synchronizes input sequences by calculating the Euclidean distance between latent vectors. This process allows similar motions to appear close to each other in the latent space. The network is trained using the golf swings of advanced golfers, so a small difference is computed when the input motion is performed similarly to advanced golfers. Conversely, if the poses between the two input motions are dissimilar in a specific frame, causing a large distance between the aligned latent vectors, a significant motion difference may be found in that frame."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of the embedder network in the TCC algorithm?\nAnswer: "}, {"role": "assistant", "content": "The embedder network in the TCC algorithm plays a crucial role in processing the output of the base network and embedding it into the latent space. It first stores the features of any given frame along with its context frames over time. Then, it applies 3D convolutions to aggregate the temporal information and reduces the dimensionality using 3D max-pooling. Finally, it uses two fully connected layers and a linear projection to obtain a 128-dimensional embedding for each frame."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\nQuery: What is the role of the embedder network in the TCC algorithm?\nOriginal Answer: The embedder network in the TCC algorithm plays a crucial role in processing the output of the base network and embedding it into the latent space. It first stores the features of any given frame along with its context frames over time. Then, it applies 3D convolutions to aggregate the temporal information and reduces the dimensionality using 3D max-pooling. Finally, it uses two fully connected layers and a linear projection to obtain a 128-dimensional embedding for each frame.\nNew Answer: "}, {"role": "assistant", "content": "The function of the embedder network in the TCC algorithm is critical as it processes the base network's output and embeds it into a latent space. It initially captures the features of a particular frame and its contextual frames over a period of time. It then employs 3D convolutions to compile the temporal data and diminishes the dimensionality using 3D max-pooling. Ultimately, it utilizes two fully connected layers and a linear projection to generate a 128-dimensional embedding for each frame."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nframe showing a particular moment, and the phase is a time\nseries between two key events. For example, as shown in\nFigure 5, a key event in golf may be the moment when the golf\nclub hits the ball (impact), and the motion before the golf club\nhits the ball can be considered as the phase of the golf club\napproaching the ball (swinging down). Note that all the\nframes in the period between two key events have the same\nphase label. Following the key event annotation of GolfDB,\nwe labeled our pseudo dataset with eight key events: address,\ntoe-up, mid-backswing, top, mid-downswing, impact, mid-\nfollow-through, and \ufb01nish. Phases were labeled between\nevery two key events, for a total of seven phases.\nThe phase classi\ufb01cation accuracy was per frame phase\nclassi\ufb01cation. To calculate the accuracy, we \ufb01rst used the\nencoders of our TCC networks to extract latent vectors.\nWe then trained a simple classi\ufb01er on the latent vectors to\npredict the labeled phases. The classi\ufb01er was trained under\nseveral conditions by changing the percentage of the given\nlabeled data. After the classi\ufb01er was trained, we used all\nlabeled data to calculate the phase classi\ufb01cation accuracy.\nIn general, the larger the size of the given labeled data, the\nhigher the accuracy of the classi\ufb01er.\nTo explore more speci\ufb01cally the effectiveness of the net-\nwork in detecting discrepant motion, we investigated whether\nthe distance in the latent space could represent the discrep-\nancy between two input sequences by computing Pearson\u2019s\ncorrelation coef\ufb01cient. Because 3D poses varied for differ-\nent camera views, we could not directly compare the two\nhuman poses using the results from the 3d pose estimator.\nThus, we applied Procrustes analysis to align the two human\nposes to ensure that they were seen from the same camera\ndirection. In our experiment, we compared the distance in the\nlatent space with the mean per joint point error (MPJPE) and\nmeasured the Pearson\u2019s correlation coef\ufb01cient \u03c1:\n\u03c1D,E=cov(D, E)\n\u03c3D\u03c3E(6)\nwhere covis the covariance; Dis the distance in the latent\nspace; Eis the MPJPE; and \u03c3Dand\u03c3Eare the standard\ndeviations of DandE.\nV. RESULTS\nThis chapter presents the results of an early qualitative\nanalysis investigating the potential of the proposed method\nto detect discrepant motion differences, followed by more\ndetailed results comparing different modules. Finally, the\nintermediate human poses generated by the motion manip-\nulator are visualized for qualitative studies.\nA. CASE STUDY\nIn our early study, we conducted a qualitative analysis by\nexploring the latent space to investigate whether the network\ncould trace \ufb01ne-grained differences. We \ufb01rst used the V-TCC\nto synchronize the swing motions of professionals and begin-\nners. We then computed the distances between the aligned\nvideos in the latent space\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the TCC algorithm align video inputs with different phasing and timing?\nAnswer: "}, {"role": "assistant", "content": "The TCC (Temporal Cycle Consistency) algorithm aligns video inputs with different phasing and timing through a process that involves several steps. First, an encoder compresses two motion sequences into latent vectors L1 and L2. For each node of L1, the algorithm finds the nearest node of L2. Then, for each identified node of L2, it finds the nearest node of L1, cycling back. If the node cycles back to itself, there is no loss. If not, a TCC loss is calculated. This method allows the network to learn not only the similarity of motion but also the temporal order of the entire motion."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: Dis the distance in the latent\nspace; Eis the MPJPE; and \u03c3Dand\u03c3Eare the standard\ndeviations of DandE.\nV. RESULTS\nThis chapter presents the results of an early qualitative\nanalysis investigating the potential of the proposed method\nto detect discrepant motion differences, followed by more\ndetailed results comparing different modules. Finally, the\nintermediate human poses generated by the motion manip-\nulator are visualized for qualitative studies.\nA. CASE STUDY\nIn our early study, we conducted a qualitative analysis by\nexploring the latent space to investigate whether the network\ncould trace \ufb01ne-grained differences. We \ufb01rst used the V-TCC\nto synchronize the swing motions of professionals and begin-\nners. We then computed the distances between the aligned\nvideos in the latent space and visualized the overlaid 3D\nhuman poses for qualitative comparison (Figure 6).TABLE 1. Phase classification accuracy. This is the accuracy metric\nshowing the ability of the network to classify any given motion frame to\nits corresponding phase.\nB. PHASE CLASSIFICATION ACCURACY\nWe trained the V-TCC using the GolfDB video dataset with\nand without background subtraction. In contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7).\nQuery: How does the TCC algorithm align video inputs with different phasing and timing?\nOriginal Answer: The TCC (Temporal Cycle Consistency) algorithm aligns video inputs with different phasing and timing through a process that involves several steps. First, an encoder compresses two motion sequences into latent vectors L1 and L2. For each node of L1, the algorithm finds the nearest node of L2. Then, for each identified node of L2, it finds the nearest node of L1, cycling back. If the node cycles back to itself, there is no loss. If not, a TCC loss is calculated. This method allows the network to learn not only the similarity of motion but also the temporal order of the entire motion.\nNew Answer: "}, {"role": "assistant", "content": "The Temporal Cycle Consistency (TCC) algorithm aligns video inputs with different phasing and timing through a series of steps. Initially, an encoder condenses two motion sequences into latent vectors L1 and L2. For every node in L1, the algorithm identifies the closest node in L2. Subsequently, for each detected node in L2, it locates the closest node in L1, creating a cycle. If the node cycles back to its original position, there is no loss. However, if it doesn't, a TCC loss is computed. This technique enables the network to understand not just the motion's similarity but also the temporal sequence of the entire motion."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the AI Golf system described in the document?\nAnswer: "}, {"role": "assistant", "content": "The purpose of the AI Golf system described in the document is to provide a golf swing analysis tool that uses deep neural networks. This tool helps users recognize the difference between their own swing motion and that of an expert, obtained from sources like the internet or broadcasted media. It is designed to offer users interpretable clues to understand the difference between their swing and professional players. The system also provides intermediate poses that are acceptable during the early learning phase of sports. It aims to make it easier for users to improve their golf skills by understanding and correcting their motions."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\nQuery: What is the purpose of the AI Golf system described in the document?\nOriginal Answer: The purpose of the AI Golf system described in the document is to provide a golf swing analysis tool that uses deep neural networks. This tool helps users recognize the difference between their own swing motion and that of an expert, obtained from sources like the internet or broadcasted media. It is designed to offer users interpretable clues to understand the difference between their swing and professional players. The system also provides intermediate poses that are acceptable during the early learning phase of sports. It aims to make it easier for users to improve their golf skills by understanding and correcting their motions.\nNew Answer: "}, {"role": "assistant", "content": "The AI Golf system described in the document is designed to assist users in improving their golf skills by analyzing their swing motions using deep neural networks. It provides users with the ability to compare their own swing with that of professional players, helping them understand the discrepancies and make necessary adjustments. The system also generates intermediate poses that are beneficial during the initial stages of learning. The ultimate goal of this system is to facilitate self-training and enhance users' performance by providing them with a better understanding of their own motions and how to refine them."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the system align two temporal sequences in order to compare them?\nAnswer: "}, {"role": "assistant", "content": "The system uses a method called dynamic time warping (DTW) to align two temporal sequences for comparison. In this method, every index in one sequence is matched with one or more indices from another sequence. The mapping of the indices from the first sequence to the other sequences must be monotonically increasing. This method has been used in various domains including golf swing projection systems and speech-to-lip movement matching."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the difference between the two approaches to abnormal detection mentioned in the document?\nAnswer: "}, {"role": "assistant", "content": "The first approach to abnormal detection refers to abnormal information as prior knowledge. For instance, a binary classifier is trained on annotated data to determine whether abnormal events occurred. In the second approach, abnormal information is not provided in advance. Instead, an unsupervised learning method is used for learning normal human behavior, using a hierarchical representation of the appearance and action level of regular movements to detect abnormal events."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nindividuals, we must align the motions to make them com-\nparable. A conventional method for aligning two temporal\nsequences is dynamic time warping (DTW), which was intro-\nduced by Berndt and Clifford [18]. In this method, every\nindex in a sequence is matched with one or more indices from\nanother sequence, and the mapping of the indices from the\n\ufb01rst sequence to the other sequences must be monotonically\nincreasing. The DTW concept has been introduced in several\ndomains. For example, Ikeda et al. [19] proposed a real-time\ngolf swing projecting system that simultaneously visualized\nprofessional and user forms with matched timing. To align\nthe two motions in real-time, they measured the DTW only\nover a short period and penalized the previous cost value at\na later time. Halperin et al. [20] utilized the concept of DTW\nin speech and presented an audio-to-video alignment method\nfor matching speech-to-lip movements.\nOn the other hand, self-supervised neural networks have\nrecently been developed to tackle video alignment tasks\nusing the latent space representation [12], [21], [22]. In this\napproach, an embedder is used to compress input videos\ninto a latent space. After the embedding process, a loss is\ndesigned to \ufb01nd correspondences through time in the latent\nspace, thus encouraging the network to learn a latent space\nwhere similar motions should appear to be close. This method\nhelps synchronize high complexity temporal sequences, such\nas videos. In this study, we base the loss of our network on the\ntemporal cycle-consistency loss used by Dwibedi et al. [12],\nbut apply DTW along with the loss for smooth temporal\nmatching.\nC. DISCREPANCY DETECTION\nBy comparing the two synchronized motions, we can deter-\nmine the difference between them in terms of human pos-\ntures. In early studies, abnormal detection referred mainly\nto \ufb01nding patterns in data that did not match the expected\nbehavior [25]. Recently, two methods have been proposed for\ndetecting abnormalities In the \ufb01rst approach, abnormal infor-\nmation is referred to as prior knowledge. For example, Parra-\nDominguez et al. [26] trained a binary classi\ufb01er on annotated\ndata to determine whether abnormal events occurred during\na stair descent. In the second approach to abnormal detec-\ntion, abnormal information is not provided in advance. The\nresearch group of Nater et al. [27] proposed an unsupervised\nlearning method for learning normal human behavior. They\nused a hierarchical representation of the appearance and\naction level of regular movements to detect abnormal events.\nWhile a network may be trained to detect abnormal events,\nsuch as falling to the ground, we focus on whether a neural\nnetwork can be trained to automatically detect \ufb01ne-grained\ndifferences between two regular motions. We call this detec-\ntion of the \ufb01ne-grained difference discrepancy detection. The\nmost relevant of these studies is that of Abati et al. [28]. They\ndesigned a deep autoencoder with a parametric estimator\nthat learned a probability distribution from the latent space\nto detect discrepancies. The encoder effectively remembered\nstandard samples and could distinguish between normal and\nFIGURE 1. System overview. Xis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion synchronization process work in the proposed system?\nAnswer: "}, {"role": "assistant", "content": "The motion synchronization process in the proposed system starts with receiving two motion inputs, X1 and X2. These inputs are then embedded into a latent space using an encoder, resulting in two representations, L1 and L2. The encoder is trained to create a latent space where similar motions are close to each other. The motion synchronizer then matches the timing of the two motions in the latent space by measuring the Euclidean distance between L1 and L2. This results in two synchronized latent vectors, V1 and V2. The difference between these vectors is then measured and passed as a distance vector D12 to the motion manipulator. This process is designed to align motion sequences with different timing."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of the motion discrepancy detector in the system?\nAnswer: "}, {"role": "assistant", "content": "The motion discrepancy detector in the system is responsible for identifying fine-grained differences in motion. After the network is trained, similar motions are close together in the latent space. The detector focuses on the distance between two motions in this latent space to detect and retrieve fine-grained discrepancies. It compares two different swing forms, particularly the differences between beginners and experts. It takes the latent vectors of the input motions, which are timing-matched by the motion synchronizer, and calculates the frame-by-frame distance vector, which indicates the degree of difference between the motions."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion manipulator integrate the synchronized motions and the distance vector?\nAnswer: "}, {"role": "assistant", "content": "The motion manipulator integrates the two synchronized latent vectors, V1 and V2, and the distance vector D12. It uses these to identify the key frames where large differences occur and creates an intermediate latent vector, Vinter. The system then uses a decoder to restore the intermediate human poses from Vinter, which helps users to gradually improve their motion forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\n\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the motion synchro-nizer in the AI Golf system?\nAnswer: "}, {"role": "assistant", "content": "The motion synchronizer in the AI Golf system is designed to align motions with different phases and timings. This is a crucial part of the process as it allows for a more accurate comparison between the user's golf swing and that of a professional player."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\nQuery: What is the purpose of the motion synchro-nizer in the AI Golf system?\nOriginal Answer: The motion synchronizer in the AI Golf system is designed to align motions with different phases and timings. This is a crucial part of the process as it allows for a more accurate comparison between the user's golf swing and that of a professional player.\nNew Answer: "}, {"role": "assistant", "content": "The motion synchronizer in the AI Golf system is utilized to align golf swings that have varying phases and timings. It plays a vital role in enabling precise comparisons between the golf swing of a user and a professional player, which is essential for the system's effectiveness."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the system use the latent space to compare user motions with those of professionals?\nAnswer: "}, {"role": "assistant", "content": "The system first trains a neural network with professionals' motion data. After this training, the system compresses the user's motions through the network into a latent space. In this latent space, the system compares the user's motions with those of professionals. The system receives two motion inputs and uses an encoder to embed these inputs into the latent space, where they are represented as two separate entities. The motion synchronizer then matches the timing of the two motions in the latent space by measuring the Euclidean distance between them. The motion discrepancy detector captures the two synchronized latent vectors, measures the difference between them, and passes a distance vector to the motion manipulator. The motion manipulator integrates these vectors to specify the key frames where large differences occur and create an intermediate latent vector. The system then uses a decoder to restore the intermediate human poses for users to gradually improve their motion forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106290\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 4. Three types of datasets.\nC. MOTION MANIPULATOR: DISCOVERING\nINTERMEDIATE MOTION BETWEEN HUMAN POSES\nDuring self-training, it is not always simple for beginners\nto imitate an ideal motion form, which is very different\nfrom their current form. In this study, we propose a motion\ndecoder to generate an intermediate motion. As mentioned\npreviously, the TCC network is trained to learn a latent space\nthat shows motion similarity. Therefore, we understand that\na high-dimensional data point in latent space can be rep-\nresentative of a human pose. To retrieve the intermediate\nmotion between two points in the latent space, we train a\ndecoder using latent vectors to predict human poses that\nare the same as the inputs. In particular, we \ufb01rst input the\ntraining set data into the trained TCC network to obtain the\noutputs of the latent vectors. Next, using the latent vectors\nas inputs, we trained a simple decoder consisting of a single\nfully-connected layer to produce the outputs of the human\nposes. For the loss function LMSE, we take the mean square\nerror (MSE) between the output and input poses:\nLMSE=\u2211\ni||Yi\u2212Xi||2(4)\nwhere Xiis the ithjoint of the input human pose XandYiis\ntheithjoint of the output human pose Y.\nAfter training the motion decoder, we retrieve a new latent\nvector Vinterbetween the two timing-matched latent vectors\nusing linear interpolation:\nVinter=(1\u2212\u03b1)\u00d7V1+\u03b1\u00d7V2 (5)\nwhere V1andV2are the two latent vectors synchronized by\nthe motion synchronizer, and \u03b1\u22080.0,1.0 is the magnitude\nparameter. In the above formulation, by increasing the value\nof\u03b1, we can obtain a human pose whose latent vector is closer\ntoV2, and the restored human pose should ideally be more\nsimilar to the human poses generated from V2.\nIV. EXPERIMENTAL SETUP\nTo evaluate the accuracy and effectiveness of the three mod-\nules introduced in the previous section, we collected golf\nswing data via the Internet and created a pseudo database\nconsisting of raw video data, without-background-video data,\nand 3D pose data (Figure 4). Next, we implemented three\nmodels of the network (V-TCC, S-TCC, and SA-TCC) uti-\nlizing TCC loss and conducted statistical analysis under four\ndifferent conditions:\n\u2022V-TCC using video inputs with backgrounds\nFIGURE 5. Key event and phase. The impact moment and the top moment\nare labeled as key events. Frames between them are labeled as swinging\ndown phases.\n\u2022V-TCC using video inputs without backgrounds\n\u2022S-TCC using 3D human pose inputs\n\u2022SA-TCC using 3D human pose inputs\nThe following sections introduce the data collection pro-\ncess and the evaluation metrics used in this study.\nA. VIDEO DATASET\nAs the training dataset, we used GolfDB [33], a video dataset\ncollection for all types of golf iron swings and driver swings,\nconsisting of 1400 high-quality golf swing videos of male and\nfemale professional golfers. Although the GolfDB provided\npreprocessed video clips for a frame size of 160 \u00d7160,\nwe rebuilt our pseudo dataset with high-resolution videos.\nIn addition to clean videos, we created another video dataset\nwithout background information. This was because, in our\nhypothesis, the background information, for example, the\nhuman shadow, might in\ufb02uence the alignment of the network.\nMoreover, the network might also learn the motion of props,\nsuch as golf clubs. We used Mask R-CNN [34], a generic\nobject detection and segmentation network, to detect the\nhuman body in a single image frame. We then removed the\nbackground pixels and left only the human body (Figure 4).\nB. 3D POSE DATASET\nTo conduct a more precise analysis of only human poses,\nwe created a new pseudo dataset consisting of 3D point\ndata of human body poses. In this dataset, we \ufb01rst used\nHRNet [35] to retrieve the time series of 2D human poses\nfrom golf-swing videos.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of the decoder in the system?\nAnswer: "}, {"role": "assistant", "content": "The decoder's role in the system is to restore the intermediate human poses from the intermediate latent vector. This is done to help users gradually improve their motion forms. Additionally, in the motion manipulator, the decoder is used to generate an intermediate motion and to predict human poses that are the same as the inputs."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc. 9th Nordic Conf. Hum.-Comput. Interact., New York, NY, USA,\nOct. 2016, pp. 1\u201310, doi: 10.1145/2971485.2971521.\n[2] C.-C. Liao, D.-H. Hwang, and H. Koike, \u2018\u2018How can i swing like pro?: Golf\nswing analysis tool for self training,\u2019\u2019 in Proc. SIGGRAPH Asia Posters,\nNew York, NY, USA, Dec. 2021, pp. 1\u20132, doi: 10.1145/3476124.3488645.\n[3] P.-H. Han, Y.-S. Chen, Y. Zhong, H.-L. Wang, and Y.-P. Hung, \u2018\u2018My Tai-\nChi coaches: An augmented-learning tool for practicing Tai-Chi Chuan,\u2019\u2019\ninProc. 8th Augmented Hum. Int. Conf., New York, NY, USA, Mar. 2017,\npp. 1\u20134, doi: 10.1145/3041164.3041194.\n[4] I. Kuramoto, Y. Nishimura, K. Yamamoto, Y. Shibuya, and Y. Tsujino,\n\u2018\u2018Visualizing velocity and acceleration on augmented practice mirror self-\nlearning support system of physical motion,\u2019\u2019 in Proc. 2nd IIAI Int.\nConf. Adv. Appl. Informat., Aug. 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep transfer\nlearning for intelligent cellular traf\ufb01c prediction based on cross-domain\nbig data,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1389\u20131401,\nJun. 2019, doi: 10.1109/JSAC.2019.2904363.\n[7] E. Wu and H. Koike, \u2018\u2018FuturePose\u2014Mixed reality martial arts training\nusing real-time 3D human pose forecasting with a RGB camera,\u2019\u2019 in Proc.\nIEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2019, pp. 1384\u20131392,\ndoi:10.1109/WACV.2019.00152.\n[8] K. Shiro, K. Egawa, T. Miyaki, and J. Rekimoto, \u2018\u2018InterPoser: Visual-\nizing interpolated movements for bouldering training,\u2019\u2019 in Proc. IEEE\nConf. Virtual Reality 3D User Inter. (VR), Mar. 2019, pp. 1563\u20131565, doi:\n10.1109/VR.2019.8798366.\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the system help users improve their motion forms?\nAnswer: "}, {"role": "assistant", "content": "The system helps users improve their motion forms by allowing them to understand the difference between their movements and those of experts. It provides step-by-step changes between two selected human poses, enabling users to gradually learn an ideal form rather than directly imitating it. Users can choose an ideal form to imitate and learn to play sports during self-training without the need for a coach. The system aims to help users efficiently learn an ideal form and refine their movements."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\n\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the purpose of the proposed golf swing analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The proposed golf swing analysis tool is designed to help users improve their golf swing by comparing their motion to that of professional players. The tool uses neural networks to identify keyframes where significant differences can be observed between the user's motion and the professional's. It also provides interpretable clues to help users understand these differences and learn how to correct their movements. The tool is intended to target the fine-grained differences between users and professionals that can be used for self-training, and it employs an unsupervised learning method without prior knowledge and labeled data."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\nQuery: What is the purpose of the proposed golf swing analysis tool?\nOriginal Answer: The proposed golf swing analysis tool is designed to help users improve their golf swing by comparing their motion to that of professional players. The tool uses neural networks to identify keyframes where significant differences can be observed between the user's motion and the professional's. It also provides interpretable clues to help users understand these differences and learn how to correct their movements. The tool is intended to target the fine-grained differences between users and professionals that can be used for self-training, and it employs an unsupervised learning method without prior knowledge and labeled data.\nNew Answer: "}, {"role": "assistant", "content": "The golf swing analysis tool aims to enhance users' golf swings by comparing their movements with those of experts. It employs advanced neural networks to pinpoint frames where substantial differences between the user's and professional's motions are evident. The tool also offers comprehensible hints to assist users in deciphering these differences and learning to adjust their actions. The tool's primary focus is on the minute disparities between users and professionals, which can be utilized for self-training. It uses an unsupervised learning approach that doesn't require prior knowledge or labeled data."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nframe showing a particular moment, and the phase is a time\nseries between two key events. For example, as shown in\nFigure 5, a key event in golf may be the moment when the golf\nclub hits the ball (impact), and the motion before the golf club\nhits the ball can be considered as the phase of the golf club\napproaching the ball (swinging down). Note that all the\nframes in the period between two key events have the same\nphase label. Following the key event annotation of GolfDB,\nwe labeled our pseudo dataset with eight key events: address,\ntoe-up, mid-backswing, top, mid-downswing, impact, mid-\nfollow-through, and \ufb01nish. Phases were labeled between\nevery two key events, for a total of seven phases.\nThe phase classi\ufb01cation accuracy was per frame phase\nclassi\ufb01cation. To calculate the accuracy, we \ufb01rst used the\nencoders of our TCC networks to extract latent vectors.\nWe then trained a simple classi\ufb01er on the latent vectors to\npredict the labeled phases. The classi\ufb01er was trained under\nseveral conditions by changing the percentage of the given\nlabeled data. After the classi\ufb01er was trained, we used all\nlabeled data to calculate the phase classi\ufb01cation accuracy.\nIn general, the larger the size of the given labeled data, the\nhigher the accuracy of the classi\ufb01er.\nTo explore more speci\ufb01cally the effectiveness of the net-\nwork in detecting discrepant motion, we investigated whether\nthe distance in the latent space could represent the discrep-\nancy between two input sequences by computing Pearson\u2019s\ncorrelation coef\ufb01cient. Because 3D poses varied for differ-\nent camera views, we could not directly compare the two\nhuman poses using the results from the 3d pose estimator.\nThus, we applied Procrustes analysis to align the two human\nposes to ensure that they were seen from the same camera\ndirection. In our experiment, we compared the distance in the\nlatent space with the mean per joint point error (MPJPE) and\nmeasured the Pearson\u2019s correlation coef\ufb01cient \u03c1:\n\u03c1D,E=cov(D, E)\n\u03c3D\u03c3E(6)\nwhere covis the covariance; Dis the distance in the latent\nspace; Eis the MPJPE; and \u03c3Dand\u03c3Eare the standard\ndeviations of DandE.\nV. RESULTS\nThis chapter presents the results of an early qualitative\nanalysis investigating the potential of the proposed method\nto detect discrepant motion differences, followed by more\ndetailed results comparing different modules. Finally, the\nintermediate human poses generated by the motion manip-\nulator are visualized for qualitative studies.\nA. CASE STUDY\nIn our early study, we conducted a qualitative analysis by\nexploring the latent space to investigate whether the network\ncould trace \ufb01ne-grained differences. We \ufb01rst used the V-TCC\nto synchronize the swing motions of professionals and begin-\nners. We then computed the distances between the aligned\nvideos in the latent space and visualized the overlaid 3D\nhuman poses for qualitative comparison (Figure 6).TABLE 1. Phase classification accuracy. This is the accuracy metric\nshowing the ability of the network to classify any given motion frame to\nits corresponding phase.\nB. PHASE CLASSIFICATION ACCURACY\nWe trained the V-TCC using the GolfDB video dataset with\nand without background subtraction. In contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7).\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the motion synchronizer align motions with different phases and timings?\nAnswer: "}, {"role": "assistant", "content": "The motion synchronizer aligns motion sequences with different timings by learning a latent space that shows motion similarity. This is achieved by constructing an autoencoder and decoder, whose input and output are the same motions. The system receives two motion inputs and uses an encoder to embed these inputs into the latent space, where the two motions are represented as two different latent vectors. The motion synchronizer then matches the timing of the two motions in the latent space by measuring the Euclidean distance between these two vectors."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nSelf-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\nB. MOTION DISCREPANCY DETECTOR: FINDING\nFINE-GRAINED MOTION DIFFERENCES\nAfter training the network, similar motions must be close\ntogether in the latent space. In this section, we focus on\nthe distance between two motions in the latent space to\ndetect and retrieve \ufb01ne-grained discrepancies and compare\ntwo different swing forms, particularly for the differences\nbetween beginners and experts. As previously mentioned, the\nTCC network synchronizes the input sequences by calculat-\ning the Euclidean distance between latent vectors. At this\npoint, similar motions appear close to each other in the latent\nspace. As shown in Figure 3, because we assume that the\nnetwork is trained using the golf swings of advanced golfers,\na small difference is computed when the input motion is\nperformed similarly to advanced golfers. On the other hand,\nif the poses between the two input motions are dissimilar in a\nspeci\ufb01c frame, causing a large distance between the aligned\nlatent vectors, we may \ufb01nd a signi\ufb01cant motion difference\nin that frame. Therefore, we take the latent vectors of the\ninput motions V1andV2, which are timing-matched by\nthe motion synchronizer, and calculate the frame-by-frame\ndistance vector D, which indicates the degree of difference\nbetween the motions:\nDi=\u2211\ni||V1i\u2212V2i||2(3)\nVOLUME 10, 2022 106289\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the role of the motion discrepancy detector in the analysis tool?\nAnswer: "}, {"role": "assistant", "content": "The motion discrepancy detector in the analysis tool is responsible for finding fine-grained motion differences. After the network is trained, similar motions are supposed to be close together in the latent space. The detector focuses on the distance between two motions in this latent space to identify and retrieve fine-grained discrepancies, and to compare two different swing forms, particularly the differences between beginners and experts. It calculates the frame-by-frame distance vector, which indicates the degree of difference between the motions. If the poses between the two input motions are dissimilar in a specific frame, causing a large distance between the aligned latent vectors, a significant motion difference in that frame may be found."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106289\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nshown that cycle-consistency methods are useful for aligning\nvideo inputs with different phasing and timing. Our method\nis inspired by the temporal cycle consistency (TCC) learning\nmethod proposed by Dwibedi et al. [12]. The TCC network is\ndesigned to allow the network to learn not only the similarity\nof motion, but also the temporal order of the entire motion.\nInspired by this previous study, we implement the TCC algo-\nrithm as follows:\n\u2022The encoder Ecompresses two motion sequences to\nlatent vectors L1,L2.\n\u2022For each node of L1, \ufb01nd the nearest node of L2.\n\u2022For each identi\ufb01ed node of L2, we \ufb01nd the nearest node\nofL1(cycle back).\n\u2022If the node is cycling back to itself, there is no loss;\notherwise, TCC loss is calculated.\nFor the encoder network, we implement a video-based\nnetwork and two skeleton-based networks. Each network\nconsists of a base network and an embedder network. While\nthe base network is designed to extract features from a given\nvideo or skeleton sequence, the embedder network uses the\noutput of the base network and embeds it into the latent space.\nFor the embedder network, we \ufb01rst store the features of any\ngiven frame together with its context frames along the time\ndimension. Next, we apply 3D convolutions to aggregate the\ntemporal information and reduce the dimensionality using 3D\nmax-pooling. Finally, we use two fully connected layers and a\nlinear projection to obtain a 128-dimensional embedding for\neach frame.\nThree types of networks are implemented in the base net-\nworks: video TCC (V-TCC), skeleton TCC (S-TCC), and\nskeleton-attention TCC (SA-TCC). V-TCC is a network that\nuses videos as its input. The original TCC implementation\nis followed to construct the V-TCC. We use the ResNet-50\n[31] architecture pre-trained with ImageNet [32] to extract\nfeatures from the output of the Conv4c layer. All frames\nin a given video sequence are resized to 224 \u00d7224, and\nthe extracted convolutional features are 14 \u00d714\u00d71024.\nThe convolutional features produced are then fed into the\nembedder network.\nS-TCC is a straightforward implementation of our baseline\nmethod that uses skeletons (human poses) as its input. The\nS-TCC consists of only fully-connected layers. All frames in\na given skeleton sequence have a size of 3 \u00d716 (joints), and\nwe expand the skeleton input to a single 1 \u00d748 vector and\nfeed it to the embedder network.\nBecause the plain implementation of S-TCC may not be\nable to learn the relationship among the 3D joints, SA-TCC\nis another skeleton input version of our TCC network that\nuses the concept of the self-attention mechanism. As shown\nin Figure 2, in the SA-TCC network, we \ufb01rst expand the 3 \u00d7\n16 skeleton input to a single 1 \u00d748 vector xand then turn\nit to query q(x), key k(x), and value v(x). The output yof\nthe attention block is fed to the embedder network, and the\ntransformation in the attention block is formulated as follows:\n\u03b2ij=exp(s ij)\u2211\niexp(s ij),where s=q(x)Tk(x) (1)\nFIGURE 2. Self-attention block. xis the skeleton input, and yis the\noutput. q(x),k(x), and v(x) is the production of the query, key, value\nrespectively.\u2a02is the matrix multiplication.\nFIGURE 3. Discrepancy detection. The proposed network is encouraged to\nfind a latent space where similar motions appear to be close. After\nsynchronization, frames with large distances in the latent space are\nconsidered keyframes where large motion differences occur.\nyi=f(\u2211\nj\u03b2ijv(x) j) (2)\nIn the above transformation, the weights to be learned for\nq(x), k(x), and v(x) are implemented as 1 \u00d71 convolutions.\nWe aim to enable the network to recognize the relationships\nbetween different skeleton joints by learning the attention\nmatrix inside the attention block.\n\npage_label: 106291\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nIn contrast, S-TCC and\nSA-TCC were trained using the pseudo skeleton dataset\nwith unit vector normalization. After training the four mod-\nels, we computed the phase classi\ufb01cation accuracy for each\ntrained model by assigning 1%, 5%, 10%, 30%, and 80% of\nlabeled data.\nThe results are presented in Table 1. As we trained the\nnetwork properly, the phase classi\ufb01cation accuracy was low\nwhen the given labeled data were insuf\ufb01cient and rose with\nan increase in the number of labeled data.\nC. CORRELATION\nWe computed Pearson\u2019s correlation coef\ufb01cient using the\nfour models. For video inputs, a 0.69 Pearson\u2019s correla-\ntion coef\ufb01cient was measured for regular video, and a\n0.72 Pearson\u2019s correlation coef\ufb01cient was obtained when the\nbackground was removed (Figure 7). For skeleton inputs,\nan over 0.76 Pearson\u2019s correlation coef\ufb01cient was found\nwhen using the SA-TCC; however, the lowest Pearson\u2019s cor-\nrelation coef\ufb01cient with 0.51 was obtained from the S-TCC\n(Figure 8).\nD. MOTION INTERPOLATION\nFor the qualitative results, we computed and visualized the\nintermediate human pose between a pair of human poses\nconsidering the following three circumstances:\n\u2022The two poses were from a single person. The two poses\nwere in different phases (Figure 9(a)).\n\u2022The two poses were from different individuals. The two\nposes were in the same phase (Figure 9(b)).\n\u2022The two poses were from different individuals. The two\nposes were in different phases (Figure 9(c)).\nVI. DISCUSSION\nA. CASE STUDY\nIn our early case study, we observed that in most cases, when\nthe distance in the latent space was small, the difference\nbetween the two 3D poses was small(Figure 6c). On the\nother hand, when the distance was considerable, the 3D poses\nshowed more differences(Figure 6b, d). This suggested that\nthe network could distinguish between beginners and profes-\nsionals. Thus, we can use this feature to retrieve motion fea-\ntures that help users target the key moves they have to correct.\nHowever, as depicted in Figure 6(a), the distance in the latent\nspace remained large even in certain circumstances where the\nVOLUME 10, 2022 106291\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the proposed SA-TCC network outperform the previous TCC network?\nAnswer: "}, {"role": "assistant", "content": "The SA-TCC network, which stands for Skeleton-Attention Temporal Cycle Consistency, outperforms the previous TCC network by incorporating a self-attention mechanism. This mechanism allows the network to recognize the relationships between different skeleton joints by learning the attention matrix inside the attention block. The SA-TCC network also showed superior performance in terms of Pearson\u2019s correlation coefficient. For skeleton inputs, an over 0.76 Pearson\u2019s correlation coefficient was found when using the SA-TCC, while the lowest Pearson\u2019s correlation coefficient of 0.51 was obtained from the original TCC network. This indicates that the SA-TCC network was more effective at aligning and analyzing motion sequences."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\n\npage_label: 106293\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nFIGURE 9. Motion manipulation. Unseen intermediate motions between two different 3D human poses are retrieved from the latent space using\nlinear interpolation. \u03b1is the blending value. The same color of the skeleton denotes the same person.\nmotion showing no difference in the latent space, while\nthe joint difference was signi\ufb01cant. As shown in Figure 7,\na greater correlation and a more clustered distribution were\nfound when the background and golf club were removed from\nthe scene. This indicated that the network could learn the\nmotion features of the club, and that it is essential to analyze\nthe club motion when showing the difference between the two\ninput motions.\nFor the two skeleton models, an over 0.76 Pearson\u2019s corre-\nlation coef\ufb01cient was found when using the SA-TCC. On the\nother hand, only a 0.51 Pearson\u2019s correlation coef\ufb01cient could\nbe obtained from the S-TCC. Therefore, along with the results\nshown in Table 1, we found that although the S-TCC network\nhad the most remarkable performance in tackling synchro-\nnization, its limited ability to detect discrepant motions might\nbe a drawback in terms of real application implementations.\nIn contrast, SA-TCC had a superior Pearson\u2019s correlation\ncoef\ufb01cient over all other competitors while maintaining an\nacceptable phase classi\ufb01cation accuracy. Overall, the skele-\nton model with the attention module implementation outper-\nformed the video models in all aspects of evaluation. There-\nfore, based on the results, we considered the attention module\nthe best choice for actual usage. We then used SA-TCC as\nour \ufb01nal version of the TCC network for the decoder and\napplication implementation, which will be discussed in the\nnext section.\nD. MOTION INTERPOLATION\nFrom the results shown in Figure 9(a), we observed that\nthe trained decoder could restore the ground truth of human\nposes. Furthermore, the motion decoder demonstrated its\nability to generate new human poses unseen in the training\ndataset. This suggested that the TCC network could learn\n\ufb01ne-grained features of the poses of a single person. Notably,\nthe intermediate motion exhibited a continuous change from\none pose to another. From this, We could infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the function of the motion manipulator in the tool?\nAnswer: "}, {"role": "assistant", "content": "The motion manipulator in the tool serves to restore motion from the latent space based on the results of synchronization and discrepancy detection. It can retrieve intermediate human poses between two motions that do not exist in the original dataset. This feature is particularly useful for beginners as it provides them with an intermediate pose that is more acceptable to start with, rather than directly teaching them about professional forms."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: infer that the human\nFIGURE 10. Visualization of body parts for revision suggestions. The\nattention-based network focuses on different body parts at three\ndifferent phases (address, top, follow-through from left to right). The\ndensity and radius of red spheres show the intensity of the attention of\nthe network.\nposes of a motion sequence were arranged in orders in the\nhigh-dimensional latent space.\nNext, as depicted in Figure 9(c), we found that the trained\ndecoder could perform fair interpolation between different\nposes. Speci\ufb01cally, intermediate poses had the character-\nistics of two different input human poses. For example,\nwe observed continuous changes in the distance between\nlimbs from one human pose to another. This suggested that\nsimilar poses which pass through the TCC network were\nembedded in nearby points in the latent space regardless of\nthe poses from different individuals.\nFinally, as shown in Figure 9(b), the motion decoder could\ngenerate meaningful intermediate poses at an aligned time.\nWe observed that the human pose gradually changed from an\nabnormal to a standard form. This suggested that instead of\nteaching beginners directly with professionals\u2019 swing forms,\nwe could provide them with a preliminary pose that is more\nacceptable for beginners to imitate.\nVII. APPLICATIONS\nThe proposed method can be used for self-training sys-\ntems that detect discrepant motion frames using the distance\nbetween golf swings in the latent space and compare 3D\nhuman poses at the detected frames. As an application proto-\ntype, we combine the motion synchronizer, motion discrep-\nancy detector, and motion manipulator into a single graphical\nVOLUME 10, 2022 106293\nQuery: What is the function of the motion manipulator in the tool?\nOriginal Answer: The motion manipulator in the tool serves to restore motion from the latent space based on the results of synchronization and discrepancy detection. It can retrieve intermediate human poses between two motions that do not exist in the original dataset. This feature is particularly useful for beginners as it provides them with an intermediate pose that is more acceptable to start with, rather than directly teaching them about professional forms.\nNew Answer: "}, {"role": "assistant", "content": "The motion manipulator's role in the tool is to reconstruct movement from the latent space, guided by synchronization and discrepancy detection outcomes. It has the ability to extract intermediate human poses between two movements that weren't included in the original dataset. This function is especially beneficial for novices, as it offers them a more approachable starting pose, rather than immediately introducing them to expert techniques."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc. 9th Nordic Conf. Hum.-Comput. Interact., New York, NY, USA,\nOct. 2016, pp. 1\u201310, doi: 10.1145/2971485.2971521.\n[2] C.-C. Liao, D.-H. Hwang, and H. Koike, \u2018\u2018How can i swing like pro?: Golf\nswing analysis tool for self training,\u2019\u2019 in Proc. SIGGRAPH Asia Posters,\nNew York, NY, USA, Dec. 2021, pp. 1\u20132, doi: 10.1145/3476124.3488645.\n[3] P.-H. Han, Y.-S. Chen, Y. Zhong, H.-L. Wang, and Y.-P. Hung, \u2018\u2018My Tai-\nChi coaches: An augmented-learning tool for practicing Tai-Chi Chuan,\u2019\u2019\ninProc. 8th Augmented Hum. Int. Conf., New York, NY, USA, Mar. 2017,\npp. 1\u20134, doi: 10.1145/3041164.3041194.\n[4] I. Kuramoto, Y. Nishimura, K. Yamamoto, Y. Shibuya, and Y. Tsujino,\n\u2018\u2018Visualizing velocity and acceleration on augmented practice mirror self-\nlearning support system of physical motion,\u2019\u2019 in Proc. 2nd IIAI Int.\nConf. Adv. Appl. Informat., Aug. 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep transfer\nlearning for intelligent cellular traf\ufb01c prediction based on cross-domain\nbig data,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1389\u20131401,\nJun. 2019, doi: 10.1109/JSAC.2019.2904363.\n[7] E. Wu and H. Koike, \u2018\u2018FuturePose\u2014Mixed reality martial arts training\nusing real-time 3D human pose forecasting with a RGB camera,\u2019\u2019 in Proc.\nIEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2019, pp. 1384\u20131392,\ndoi:10.1109/WACV.2019.00152.\n[8] K. Shiro, K. Egawa, T. Miyaki, and J. Rekimoto, \u2018\u2018InterPoser: Visual-\nizing interpolated movements for bouldering training,\u2019\u2019 in Proc. IEEE\nConf. Virtual Reality 3D User Inter. (VR), Mar. 2019, pp. 1563\u20131565, doi:\n10.1109/VR.2019.8798366.\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nReceived 20 August 2022, accepted 18 September 2022, date of publication 6 October 2022, date of current version 11 October 2022.\nDigital Object Identifier 10.1 109/ACCESS.2022.3210261\nAI Golf: Golf Swing Analysis Tool for Self-Training\nCHEN-CHIEH LIAO\n1, DONG-HYUN HWANG\n2, AND HIDEKI KOIKE\n1\n1Department of Computer Science, Tokyo Institute of Technology, Tokyo 152-8550, Japan\n2NAVER CLOVA Voice&Avatar, Seongnam 13561, South Korea\nCorresponding author: Chen-Chieh Liao (liao.c.aa@m.titech.ac.jp)\nThis work was supported by the Japan Science and Technology Agency (JST) Core Research for Evolutional Science and Technology\n(CREST), Japan, under Grant JPMJCR17A3.\nABSTRACT In the \ufb01eld of the acquisition of sports skills, a common way to improve sports skills, such as\ngolf swings, is to imitate professional players\u2019 motions. However, it is dif\ufb01cult for beginners to specify\nthe keyframes on which they should focus and which part of the body they should correct because of\ninconsistent timing and lack of knowledge. In this study, a golf swing analysis tool using neural networks\nis proposed to address this gap. The proposed system compares two motion sequences and speci\ufb01es\nkeyframes in which signi\ufb01cant differences can be observed between the two motions. In addition, the system\nhelps users intuitively understand the differences between themselves and professional players by using\ninterpretable clues. The main challenge of this study is to target the \ufb01ne-grained differences between users\nand professionals that can be used for self-training. Moreover, the signi\ufb01cance of the proposed approach is\nthe use of an unsupervised learning method without prior knowledge and labeled data, which will bene\ufb01t\nfuture applications and research in other sports and skill training processes. In our approach, neural networks\nare \ufb01rst used to create a motion synchronizer to align motions with different phases and timing. Next,\na motion discrepancy detector is implemented to \ufb01nd \ufb01ne-grained differences between motions in latent\nspaces that are learned by the networks. Furthermore, we consider that learning intermediate motions may\nbe feasible for beginners because, in this way, they can gradually change their pose to match the ideal form.\nTherefore, based on the synchronization and discrepancy detection results, we utilize a decoder to restore\nthe intermediate human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore,\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the tool help users understand the difference between their swings and those of professional players?\nAnswer: "}, {"role": "assistant", "content": "The tool helps users understand the difference between their swings and those of professional players by comparing two motion sequences and specifying keyframes where significant differences can be observed. It uses neural networks to create a motion synchronizer to align motions with different phases and timing. Then, a motion discrepancy detector is implemented to find fine-grained differences between motions in latent spaces that are learned by the networks. Additionally, the tool uses a decoder to restore the intermediate human poses between two motions from the latent space, allowing users to gradually change their pose to match the ideal form. This way, users can intuitively understand the differences and learn how to improve their motions."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: human poses between two motions from the latent space. Finally, we suggest possible\napplications for analyzing and visualizing the discrepancy between the two input motions and interacting\nwith the users. With the proposed application, users can easily understand the differences between their\nmotions and those of various experts during self-training and learn how to improve their motions.\nINDEX TERMS Computer vision, machine learning, motor skill training, golf.\nI. INTRODUCTION\nIn sports, it is dif\ufb01cult for beginners to improve their skills\nwithout prior knowledge or assistance from coaches. As a\nconventional method, people go to lessons to meet experts\nand learn how to play in the proper form. However, in most\nsports, players spend considerable time training alone to\nachieve outstanding results in the \ufb01eld and retain exceptional\nbody conditions. Therefore, it is important to design and\nimplement an effective and accurate self-training process for\nsuch situations.\nIn the \ufb01eld of the acquisition of sports skills, one way\nto improve sports skills is to replicate professional players\u2019\nmotions. People watch the movements of professional ath-\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Jinjia Zhou\n .letes on television or the Internet and try to make their bodies\nmove similarly to professionals. To accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7].\nQuery: How does the tool help users understand the difference between their swings and those of professional players?\nOriginal Answer: The tool helps users understand the difference between their swings and those of professional players by comparing two motion sequences and specifying keyframes where significant differences can be observed. It uses neural networks to create a motion synchronizer to align motions with different phases and timing. Then, a motion discrepancy detector is implemented to find fine-grained differences between motions in latent spaces that are learned by the networks. Additionally, the tool uses a decoder to restore the intermediate human poses between two motions from the latent space, allowing users to gradually change their pose to match the ideal form. This way, users can intuitively understand the differences and learn how to improve their motions.\nNew Answer: "}, {"role": "assistant", "content": "The tool assists users in understanding the disparities between their swings and those of professional players by analyzing and comparing two separate motion sequences, pinpointing keyframes where significant variances are noticeable. It employs neural networks to construct a motion synchronizer that aligns motions with differing phases and timing. A motion discrepancy detector is then utilized to identify subtle differences between motions in latent spaces that the networks have learned. The tool also incorporates a decoder to reconstruct the intermediate human poses between two motions from the latent space, enabling users to gradually adjust their pose to align with the ideal form. This approach allows users to intuitively comprehend the differences and learn how to enhance their motions."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106288\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nXis the input motion sequence and Yis the\noutput human poses restored from the latent space.\nabnormal images. However, although the network could eas-\nily detect surprise samples, \ufb01ne-grained differences among\nstandard samples were not discussed. In addition to image-\nbased methods, recent studies have focused on systems that\nuse 3D human pose information [29], [30]. In this study,\nwe apply discrepancy detection to both videos and 3D\nhuman poses and discuss the ability of the system to detect\n\ufb01ne-grained differences between two input motions.\nIII. METHODS\nThis study aims to create a system that captures user motions\nand provides \ufb01ne-grained feedback to improve users\u2019 forms\nby comparing their motions with those of professionals.\nTo achieve the goal of building such an application, the\nmethod proposed in this study is to \ufb01rst train a neural network\nwith professionals\u2019 motion data. After training the network,\nthe system compresses the user motions through the network\ninto a latent space and compares their motions with those of\nprofessionals in the latent space. Figure 1 shows an overview\nof the proposed system. The work\ufb02ow of the approach is\ndivided into three parts: motion synchronization, motion dis-\ncrepancy detection, and motion manipulation. The system\n\ufb01rst receives two motion inputs X1andX2and uses encoder\nEto embed the input motions into the latent space, where the\ntwo motions are represented as L1andL2. The encoder is\ntrained to learn a latent space in which similar motions appear\nto be close.\nNext, using the learned latent space, the motion synchro-\nnizer MSmatches the timing of the two motions in the\nlatent space by measuring the Euclidean distance between\nL1andL2. The motion discrepancy detector then captures\nthe two synchronized latent vectors V1andV2, measures the\ndifference between them, and passes a distance vector D12to\nthe motion manipulator MM.\nFinally, the MM integrates V1,V2, and D12to specify\nthe key frames where large differences occur and create an\nintermediate latent vector Vinter. The system uses decoder D\nto restore the intermediate human poses Yfrom Vinterfor\nusers to gradually improve their motion forms.\nA. MOTION SYNCHRONIZER: ALIGNING MOTION\nSEQUENCES WITH DIFFERENT TIMING\nFor motion synchronization, we aim to design a network\nthat learns a latent space that shows motion similarity.\nA common way to achieve this is by constructing an\nautoencoder and decoder, whose input and output are the\nsame motions. On the other hand, previous studies have\n106288 VOLUME 10, 2022\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What is the potential benefit of using a high-quality motion capture system in the proposed system?\nAnswer: "}, {"role": "assistant", "content": "A high-quality motion capture system in the proposed system can provide accurate and detailed user motion data. This data can be used to train the neural network with professionals' motion data. The system can then compress the user motions through the network into a latent space and compare their motions with those of professionals. This allows the system to provide fine-grained feedback to users, helping them improve their forms by highlighting the differences between their motions and those of professionals. The system can also identify key frames where large differences occur and create an intermediate latent vector to help users gradually improve their motion forms."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc. 9th Nordic Conf. Hum.-Comput. Interact., New York, NY, USA,\nOct. 2016, pp. 1\u201310, doi: 10.1145/2971485.2971521.\n[2] C.-C. Liao, D.-H. Hwang, and H. Koike, \u2018\u2018How can i swing like pro?: Golf\nswing analysis tool for self training,\u2019\u2019 in Proc. SIGGRAPH Asia Posters,\nNew York, NY, USA, Dec. 2021, pp. 1\u20132, doi: 10.1145/3476124.3488645.\n[3] P.-H. Han, Y.-S. Chen, Y. Zhong, H.-L. Wang, and Y.-P. Hung, \u2018\u2018My Tai-\nChi coaches: An augmented-learning tool for practicing Tai-Chi Chuan,\u2019\u2019\ninProc. 8th Augmented Hum. Int. Conf., New York, NY, USA, Mar. 2017,\npp. 1\u20134, doi: 10.1145/3041164.3041194.\n[4] I. Kuramoto, Y. Nishimura, K. Yamamoto, Y. Shibuya, and Y. Tsujino,\n\u2018\u2018Visualizing velocity and acceleration on augmented practice mirror self-\nlearning support system of physical motion,\u2019\u2019 in Proc. 2nd IIAI Int.\nConf. Adv. Appl. Informat., Aug. 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep transfer\nlearning for intelligent cellular traf\ufb01c prediction based on cross-domain\nbig data,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1389\u20131401,\nJun. 2019, doi: 10.1109/JSAC.2019.2904363.\n[7] E. Wu and H. Koike, \u2018\u2018FuturePose\u2014Mixed reality martial arts training\nusing real-time 3D human pose forecasting with a RGB camera,\u2019\u2019 in Proc.\nIEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2019, pp. 1384\u20131392,\ndoi:10.1109/WACV.2019.00152.\n[8] K. Shiro, K. Egawa, T. Miyaki, and J. Rekimoto, \u2018\u2018InterPoser: Visual-\nizing interpolated movements for bouldering training,\u2019\u2019 in Proc. IEEE\nConf. Virtual Reality 3D User Inter. (VR), Mar. 2019, pp. 1563\u20131565, doi:\n10.1109/VR.2019.8798366.\n\npage_label: 106286\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nTo accelerate this process,\nmany systems have recently been developed to help users\nunderstand the movements of professionals [1], [2], [3], [4],\n[5]. However, in these previous works and systems, users may\nstruggle to re\ufb01ne their movement with no idea which timing\nof the whole motion, which parts of the body they should\nfocus on, or how they can change their body movements to\nget their form closer to that of professionals.\nWith signi\ufb01cant advances in machine learning technolo-\ngies, many systems have been built to recognize differ-\nent objects, make predictions for decisions, or even predict\nthe future [6]. Researchers have focused on producing\nself-training systems with neural networks [7]. A recent\nstudy [8] introduced a climbing training system in which\nusers can receive recommended poses and movements to\n106286This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/VOLUME 10, 2022\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the proposed tool aim to help users learn an ideal form in a gradual manner?\nAnswer: "}, {"role": "assistant", "content": "The proposed tool aims to help users learn an ideal form in a gradual manner by allowing them to understand the differences between their own swings and those of various experts. It facilitates this learning process by providing a step-by-step comparison between the user's pose and the selected expert's pose. This way, users can efficiently learn and imitate the ideal form without the need for a coach. The tool is intended to be refined further and user studies will be conducted to assess its effectiveness."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nbe learned in the future, based on their current poses, after\ntraining the network with professional poses. The advantage\nof incorporating machine learning is that the system can learn\nwithout prior knowledge. Therefore, no expert or coach is\nrequired to build such a system, and it can be generalized to\nmany other tasks. In addition, apart from image information,\nmultiple sensors have recently been fused to measure human\nmotion, and deep learning technologies can ef\ufb01ciently take\nadvantage of processing such fused data [9]. However, super-\nvised learning requires abundant data from a speci\ufb01c domain,\nwhich makes it dif\ufb01cult to design a generalized sensor fusion\napplication.\nIn this study, we address these gaps in the literature to\nprovide users with interpretable clues so that they can intu-\nitively understand the difference between themselves and\nprofessional players. We choose golf as our network learning\nsubject because golf is an individual sport, and the player\u2019s\nstanding position is \ufb01xed when performing a swing. Recent\nstudies [10], [11] have demonstrated the ability of deep\nlearning to retrieve \ufb01ne-grained information necessary for\ngolf swing analysis. However, after retrieving the essential\nfactors from human motion, the system designer must know\nwhich part of the body is vital in golf and determine which\nparts must be processed for analysis. Furthermore, the cal-\nculation is manually designed for golf swings; thus, it is\ndif\ufb01cult to generalize the proposed methods to other sports\nanalyses without prior knowledge or the help of experts.\nIn this study, we propose a golf swing analysis tool using\ndeep neural networks to help users recognize the difference\nbetween the user\u2019s swing motion and an expert\u2019s motion\nobtained from the Internet or broadcasted media. Further-\nmore, we address the previous issues in an unsupervised man-\nner to encourage the network to learn standard features from\nprofessional players without adding domain-speci\ufb01c infor-\nmation. Consequently, the proposed network can be applied\nto other sports and skill-training processes.\nThe proposed system consists of three modules: a motion\nsynchronizer, motion discrepancy detector, and motion\nmanipulator. The motion synchronizer matches the two input\nmotions with different timings and speeds. The motion dis-\ncrepancy detector can recognize the difference between the\ntwo motions and \ufb01nd the frame in which the difference\nis large. The motion manipulator is designed to produce\nintermediate motions between the two motions to provide\nmore intuitive instructions for users to learn. To evaluate the\naccuracy and effectiveness of the proposed modules, we col-\nlect golf swing data from existing databases and generate a\npseudo database containing raw video data, 3D pose data,\nand labels for the phases during the swing. Next, we examine\nthe accuracy of the motion synchronizer and the capability of\nmotion discrepancy using three types of inputs (raw video,\nvideo without background, and 3D human pose). Finally,\nwe discuss the accuracy of the results and explain the correla-\ntion among the learned latent space, human motion, and other\nfeatures. On the other hand, qualitative results are shown to\nevaluate the ability of the motion manipulator to reproducemotions from the latent space and create new motions unseen\nin the database.\nFurthermore, we discuss the proposed analytical tool and\nits possible applications in future research. The proposed\napplication visualizes the image frames and human motions\nwhere the discrepancy between the expert and the user\u2019s\nswing is large and helps the user quickly recognize the motion\nthat needs to be corrected. Compared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories.\n\npage_label: 106287\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nCompared to existing methods,\nthe main contributions of this study can be summarized as\nfollows:\n\u2022A golf swing analysis method and its applications are\nintroduced.\n\u2022The proposed method distinguishes when the difference\nbetween two motions is large and small.\n\u2022The proposed method helps users understand the differ-\nence between themselves and professional players.\n\u2022The proposed method provides intermediate poses that\nare acceptable during the early learning phase of sports.\n\u2022Crucial factors that can in\ufb02uence the accuracy of sports\nanalysis are discussed.\nII. RELATED WORK\nA. SPORTS TRAINING FOR SKILL ACQUISITION\nMany recent studies have focused on developing sports\ntraining systems to help beginners improve their skills. Stud-\nies [13], [14], [15] have proposed multi-modal sports training\nsystems based on sports theories. In their system, users\nreceived visual, haptic, and audio feedback when they did not\nideally move their bodies or instruments. However, the ideal\nmovement could differ from sport to sport, meaning that it\nmay be dif\ufb01cult to generalize these methodologies to other\nsports.\nOn the other hand, another way to learn sports skills is\nimitating professional players\u2019 motions [1], [3], [4], [5].\nIkeda et al. [16] proposed a golf swing training system that\nuses the motions of professional golfers. In their system,\na user\u2019s motion was synchronized with a selected ideal\nprofessional\u2019s motion, and the two motions were overlaid and\nprojected onto the ground during training. Sasaki et al. [17]\nalso reported the importance of beginners copying expert\nmotions and proposed a climbing training system using pose\nprediction. Their system predicted and visualized the pose of\nexperts based on the user\u2019s current hand and foot positions.\nWhile these recent studies have shown the effectiveness of\nusing multi-modal feedback and the potential of applying\nneural networks to create AI teachers for sports training, it is\ndif\ufb01cult for users to change their motion forms immediately\nto match ideal forms. Thus, building a system that can teach\nusers step-by-step to improve their sports skills remains\nchallenging.\nB. VIDEO AND MOTION ALIGNMENT\nAn ef\ufb01cient way to evaluate whether a person is performing\na motion correctly is to compare their motion with oth-\ners whose motion is considered correct. However, owing\nto the various timings and speeds of motion of different\nVOLUME 10, 2022 106287\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: What are some potential future applications of the proposed method beyond golf swing analysis?\nAnswer: "}, {"role": "assistant", "content": "The proposed method can be applied to other sports and skill-training processes. It can be used in any scenario where it's beneficial to understand and replicate the movements of professionals or experts. This could include other individual sports, physical training exercises, or even non-sport activities that require specific movements or poses."}]}
{"messages": [{"role": "system", "content": "You are an expert Q&A system that is trusted around the world.\nAlways answer the query using the provided context information, and not prior knowledge.\nSome rules to follow:\n1. Never directly reference the given context in your answer.\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines."}, {"role": "user", "content": "Context information is below.\n---------------------\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nC.-C. Liao et al.: AI Golf: Golf Swing Analysis Tool for Self-Training\nuser interface where users can select any professional\u2019s form\nfrom the database and compare the difference between their\nforms and the professional\u2019s. In addition, instead of directly\nimitating the selected motion, users can gradually imitate\nintermediate human poses using a motion manipulator. Fur-\nthermore, we visualized the attention maps along with the\nself-attention module to demonstrate the importance of each\nbody part (Figure 10). This may be a clue for discovering\nbody parts that should be focused on and what can be ignored.\nTo go a step further, this might indicate the importance of the\nbody parts that trainees should follow to revise their poses\noptimally. In the future, we plan to conduct user studies to\nevaluate the training effectiveness of the proposed system\nand determine whether the crucial points shown by the atten-\ntion maps can be used in real training scenarios. Moreover,\nwe consider that using a high-quality motion capture sys-\ntem can enhance the solidity of the proposed system with\nhigh-precision human poses despite the high speed of motion,\nsuch as golf swings.\nAs this work focuses on proposing a novel \ufb02ow for con-\nstructing a sports analysis tool, and because user studies may\nvary from domain to domain and are \ufb02exible for the system\ndesigner, further user studies evaluating the proposed sys-\ntem\u2019s ef\ufb01ciency have not been addressed in practice. As pre-\nviously mentioned, there are many ways to design a proper\nway to provide feedback to users for training. Related works\nthat use multi-modal feedback to alert users when performing\nthe wrong way compared to professionals have shown their\nsigni\ufb01cance during training. In the future, we plan to combine\nour approach with other feedback systems and evaluate the\neffectiveness of the system. Furthermore, we plan to apply the\nproposed approach to other sports and skill training processes\nto explore the generality of the proposed method.\nVIII. CONCLUSION\nWe propose a golf swing analysis tool that uses neural net-\nworks to help users intuitively understand the difference\nbetween themselves and professional players. We divide our\nwork into three parts: synchronization, discrepancy detec-\ntion, and manipulation. First, the motion synchronizer aligns\nmotions with different phases and timings. The experi-\nment shows that our implementation using skeleton inputs\ncan achieve a better performance than state-of-the-art video\nimplementations.\nSecond, using the proposed networks, we use a motion\ndiscrepancy detector to \ufb01nd \ufb01ne-grained differences between\ngolf swings in the latent space. By applying comparative anal-\nysis, such as comparing 3D human poses in those detected\nframes, we conclude that the motion discrepancy detector can\ndistinguish whether the difference between the two motions is\nsmall or large. The proposed SA-TCC network outperforms\nthe previous TCC network in terms of phase classi\ufb01cation\naccuracy and has the best ability to show the correlation\nbetween the distance in the latent space and the MPJPE.\nThird, based on the synchronization and discrepancy detec-\ntion results, we introduce a decoder structure called a motionmanipulator to restore motion from the latent space. The\nrestoration results suggest that the network can retrieve inter-\nmediate human poses between two motions that do not\nexist in the original dataset. Furthermore, instead of teach-\ning beginners directly about professional forms, the motion\nmanipulator can provide them with an intermediate pose that\nis more acceptable for beginners to start with.\nFinally, with the above three main contributions of this\nwork, we create an application for analyzing and visualiz-\ning the discrepancy between two input golf swing motions.\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc.\n\npage_label: 106294\nfile_path: test\\regression\\regression_test003\\AI_Golf_Golf_Swing_Analysis_Tool_for_Self-Training.pdf\n\nFor user interaction, users can quickly grasp the difference\nbetween their swings and those of various experts during\nself-training. In addition, by understanding the continuous\nchanges step-by-step between the two selected human poses,\nwe aim to help users ef\ufb01ciently learn an ideal form in a\ngradual manner instead of directly imitating ideal motion.\nUsing the proposed system, users can choose an ideal form\nto imitate and learn to play sports without the help of coaches\nduring self-training. We intend to re\ufb01ne the proposed pro-\ntotype application and conduct user studies to investigate its\neffectiveness.\nREFERENCES\n[1] T. N. Hoang, M. Reinoso, F. Vetere, and E. Tanin, \u2018\u2018Onebody: Remote\nposture guidance system using \ufb01rst person view in virtual environment,\u2019\u2019\ninProc. 9th Nordic Conf. Hum.-Comput. Interact., New York, NY, USA,\nOct. 2016, pp. 1\u201310, doi: 10.1145/2971485.2971521.\n[2] C.-C. Liao, D.-H. Hwang, and H. Koike, \u2018\u2018How can i swing like pro?: Golf\nswing analysis tool for self training,\u2019\u2019 in Proc. SIGGRAPH Asia Posters,\nNew York, NY, USA, Dec. 2021, pp. 1\u20132, doi: 10.1145/3476124.3488645.\n[3] P.-H. Han, Y.-S. Chen, Y. Zhong, H.-L. Wang, and Y.-P. Hung, \u2018\u2018My Tai-\nChi coaches: An augmented-learning tool for practicing Tai-Chi Chuan,\u2019\u2019\ninProc. 8th Augmented Hum. Int. Conf., New York, NY, USA, Mar. 2017,\npp. 1\u20134, doi: 10.1145/3041164.3041194.\n[4] I. Kuramoto, Y. Nishimura, K. Yamamoto, Y. Shibuya, and Y. Tsujino,\n\u2018\u2018Visualizing velocity and acceleration on augmented practice mirror self-\nlearning support system of physical motion,\u2019\u2019 in Proc. 2nd IIAI Int.\nConf. Adv. Appl. Informat., Aug. 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep\n---------------------\nGiven the context information and not prior knowledge, answer the query.\nQuery: How does the proposed tool incorporate user feedback and interaction during self-training?\nAnswer: "}, {"role": "assistant", "content": "The proposed tool allows users to interact by selecting any professional's form from the database and comparing it with their own. Users can gradually imitate intermediate human poses using a motion manipulator. The tool also visualizes attention maps to highlight the importance of each body part in the swing, which can guide users on which parts to focus on and which can be ignored. The system is designed to help users understand the differences between their swings and those of professionals, and to learn an ideal form gradually, rather than directly imitating the ideal motion."}]}
{"messages": [{"role": "user", "content": "You are an expert Q&A system that strictly operates in two modes when refining existing answers:\n1. **Rewrite** an original answer using the new context.\n2. **Repeat** the original answer if the new context isn't useful.\nNever reference the original answer or context directly in your answer.\nWhen in doubt, just repeat the original answer.New Context: 2013, pp. 365\u2013368, doi: 10.1109/IIAI-\nAAI.2013.28.\n[5] M. Kyan, G. Sun, H. Li, L. Zhong, P. Muneesawang, N. Dong, B. Elder,\nand L. Guan, \u2018\u2018An approach to ballet dance training through MS Kinect and\nvisualization in a CAVE virtual reality environment,\u2019\u2019 ACM Trans. Intell.\nSyst. Technol., vol. 6, no. 2, pp. 1\u201337, May 2015, doi: 10.1145/2735951.\n[6] C. Zhang, H. Zhang, J. Qiao, D. Yuan, and M. Zhang, \u2018\u2018Deep transfer\nlearning for intelligent cellular traf\ufb01c prediction based on cross-domain\nbig data,\u2019\u2019 IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1389\u20131401,\nJun. 2019, doi: 10.1109/JSAC.2019.2904363.\n[7] E. Wu and H. Koike, \u2018\u2018FuturePose\u2014Mixed reality martial arts training\nusing real-time 3D human pose forecasting with a RGB camera,\u2019\u2019 in Proc.\nIEEE Winter Conf. Appl. Comput. Vis. (WACV), Jan. 2019, pp. 1384\u20131392,\ndoi:10.1109/WACV.2019.00152.\n[8] K. Shiro, K. Egawa, T. Miyaki, and J. Rekimoto, \u2018\u2018InterPoser: Visual-\nizing interpolated movements for bouldering training,\u2019\u2019 in Proc. IEEE\nConf. Virtual Reality 3D User Inter. (VR), Mar. 2019, pp. 1563\u20131565, doi:\n10.1109/VR.2019.8798366.\nQuery: How does the proposed tool incorporate user feedback and interaction during self-training?\nOriginal Answer: The proposed tool allows users to interact by selecting any professional's form from the database and comparing it with their own. Users can gradually imitate intermediate human poses using a motion manipulator. The tool also visualizes attention maps to highlight the importance of each body part in the swing, which can guide users on which parts to focus on and which can be ignored. The system is designed to help users understand the differences between their swings and those of professionals, and to learn an ideal form gradually, rather than directly imitating the ideal motion.\nNew Answer: "}, {"role": "assistant", "content": "The suggested tool provides an interactive platform where users can choose a professional's form from a database and juxtapose it with their own. By using a motion manipulator, users can progressively replicate intermediate human poses. The tool also employs attention maps for visualization, emphasizing the significance of each body part in the swing. This assists users in identifying which areas require more focus and which can be disregarded. The system's objective is to aid users in discerning the disparities between their swings and those of professionals, and to progressively learn the perfect form instead of instantly mimicking the ideal motion."}]}